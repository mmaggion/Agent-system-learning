% !TEX root = dynamicslearning.tex


\section{$\Gamma$-convergence of $ \mathcal E^{[a],N} $ to $ \mathcal E^{[a]} $}



%At the end of the last section, we have seen which are the main ingredients to ensure that our error functional $E$ has the target interaction kernel $a$ as unique minimizer (the coercivity assumption \eqref{eq-coercive}), and for the well-posedness of the minimization problem of the functionals $E_N$ (the knowledge of an upper bound for $\|a\|_{L_{\infty}(\R_+)}$ and $\|a'\|_{L_{\infty}(\supp(\rho))}$).

This section is devoted to a proof of Theorem \ref{thm}.

\subsection{Uniform convergence estimates}

We start with a technical lemma.

\begin{lemma}\label{lemma-semicontinuous-0}
	Under the assumptions of Theorem \ref{thm}, let $(b_N)_{N \in \N}\subset X_{M,K}$ be a sequence of continuous functions and $b \in X_{M,K}$, for $K=[0,2R]$  with $R>0$ as in \eqref{Rest}.
	Then we have the estimate
\begin{equation}\label{approxestimate}	
\bigl|\mathcal E^{[a],N}(b_N)-\mathcal E^{[a]}(b)\bigr|
		\leq  c_1 W_1(\mu_0^N,\mu_0)+ c_2 \| b_{N}-b\|_{L_\infty(K)},
\end{equation}
where the constants are explicitly given by $c_1= 32 \overline{C}R(2R+1)M^2$ and $c_2 = 16R^2M$.
\end{lemma}

\begin{proof}
	By \eqref{stab}, $W_1(\mu(t),\mu^N(t))\leq\overline{C}W_1(\mu_0,\mu_0^N)$ uniformly in $t \in [0,T]$.
	For all $x,y,y' \in B(0,R)$, by the triangle inequality we have
	\begin{align*}
		|(\Fun{a} -\Fun{b})(x-y') - &(\Fun{a} -\Fun{b})(x- y)|  \\
			& \leq \left[2R (\Lip_K(a) + \Lip_K( b))    +\|a\|_{L_\infty(K)} + \| b\|_{L_\infty(K)} \right] |y-y'|,
	\end{align*}
	which implies the Lipschitz continuity of $(\Fun{a} -\Fun{b})(x- \cdot)$ in $B(0,R)$ for fixed $x\in B(0,R)$. Since $a,b \in X_{M,K}$, this implies
	\begin{equation}\label{lipfafb}
		\Lip_{B(0,R)}|(\Fun{a} -\Fun{b})(x-\cdot)|\leq 2 (2R+1)M,
	\end{equation}
	uniformly with respect to $x \in B(0,R)$. Consequently, we have
	\begin{align*}
		\biggl|\int_{\R^d}\bigl(\Fun{b}
			&-\Fun{a}\bigr)(x-y)d\mu^{N}(t)(y)-\int_{\R^d}\bigl(\Fun{b}-\Fun{a}\bigr)(x-y)d\mu(t)(y)\biggr|\\
			&\leq\Lip_{B(0,R)}|(\Fun{a} -\Fun{b})(x-\cdot)|\,W_1(\mu^N(t),\mu(t))
				\leq 2 \overline{C}(2R+1)M\,W_1(\mu_0^N,\mu_0),
	\end{align*}
	uniformly with respect to $t\in [0,T]$ and $x\in B(0,R)$. Furthermore, we also have
	\begin{eqnarray}
		\sup_{x,y \in B(0,R)}|\Fun{b_{N}}(x-y)-\Fun{b}(x-y)|&\leq& 2R \| b_{N}- b\|_{L_\infty(K)},\label{absbounda}\\
	\sup_{x,y \in B(0,R)}|\Fun{a}(x-y)-\Fun{b}(x-y)|	&\leq& 2R \| a- b\|_{L_\infty(K)}. \label{absbound}
	\end{eqnarray}
	Hence we further obtain
	\begin{align} \label{machecazzo}
		\Biggl|
			&\biggl|\int_{\R^d}\bigl(\Fun{b_{N}}-\Fun{a}\bigr)(x-y)d\mu^{N}(t)(y)\biggr| 
				-\biggl|\int_{\R^d}\bigl(\Fun{b}-\Fun{a}\bigr)(x-y)d\mu(t)(y)\biggr|\Biggr|\\ \nonumber
			&\leq\biggl|\int_{\R^d}\bigl(\Fun{b_{N}}-\Fun{a}\bigr)(x-y)d\mu^{N}(t)(y)
					-\int_{\R^d}\bigl(\Fun{b}-\Fun{a}\bigr)(x-y)d\mu(t)(y)\biggr|\\ \nonumber
			&\leq\Biggl|\int_{\R^d}
				\bigl(\Fun{b_{N}}-\Fun{b}\bigr)(x-y)d\mu^{N}(t)(y)\Biggr|\\ \nonumber
			&\qquad +\biggl|\int_{\R^d}\bigl(\Fun{b}-\Fun{a}\bigr)(x-y)d\mu^{N}(t)(y)
					-\int_{\R^d}\bigl(\Fun{b}-\Fun{a}\bigr)(x-y)d\mu(t)(y)\biggr|\\ \nonumber
			&\leq 2R \| b_{N}-b\|_{L_\infty(K)}\int_{\R^d}d\mu^{N}(t)(y)+ 2(2R+1)M\,W_1(\mu^N(t),\mu(t))\\ \nonumber
			&\leq 2R \| b_{N}-b\|_{L_\infty(K)}+2 \overline{C}(2R+1)M\,W_1(\mu_0^N,\mu_0). 
	\end{align}
Let
	\begin{align*}
		H_N(t,x)&=\Biggl|\int_{\R^d}\bigl(\Fun{b_{N}}-\Fun{a}\bigr)(x-y)d\mu^{N}(t)(y)\Biggr|^2\,,\quad
		&G_N(t)&= \int_{\R^d}H_N(t,x)d\mu^N(t)(x)\,,\\
		H(t,x)&= \Biggl|\int_{\R^d}\bigl(\Fun{b}-\Fun{a}\bigr)(x-y)d\mu(t)(y)\Biggr|^2\,,
		&G(t)&= \int_{\R^d}H(t,x)d\mu(t)(x).
	\end{align*}
	Then immediately it follows
	\begin{align}
		|G_N(t)-G(t)|&\leq \left|\int_{\R^d}H(t,x)d\mu^N(t)(x) - \int_{\R^d}H(t,x)d\mu(t)(x)\right| \nonumber\\
		&\quad + \int_{\R^d}\left|H_N(t,x) - H(t,x)\right|d\mu^N(t)(x). \label{aux3}
	\end{align}
From \eqref{absbound} and \eqref{lipfafb} we obtain
\begin{eqnarray*}
\Lip_{B(0,R)}H(t,\cdot)&\leq& 2 \left (\sup_{x,y \in B(0,R)}|\Fun{a}(x-y)-\Fun{b}(x-y)| \right ) \cdot\Lip_{B(0,R)}(\Fun{a} -\Fun{b})(\cdot -y) \\
&\leq& 4R\|a-b\|_{L_\infty(K)}\cdot 2(2R+1)M\,,
\end{eqnarray*}
and therefore
	\begin{align}\label{aux1}
		\left|\int_{\R^d}H(t,x)d\mu^N(t)(x) - \int_{\R^d}H(t,x)d\mu(t)(x)\right|
			&\leq\Lip_{B(0,R)}H(t,\cdot)W_1(\mu^N(t),\mu(t))\nonumber\\
			&\leq 8R(2R+1)\overline{C}M\|a-b\|_{L_\infty(K)}W_1(\mu_0^N,\mu_0)\nonumber\\
			&\leq 16R(2R+1)\overline{C}M^2 W_1(\mu_0^N,\mu_0)
	\end{align}
	uniformly in $t \in [0,T]$. Similarly, \eqref{absbounda}, \eqref{lipfafb}, and \eqref{machecazzo} imply
	\begin{align}\label{aux2}
		\bigl|H_N(t,x)-H(t,x)\bigr|
			&\leq \Bigl(2R \| b_{N}-b\|_{L_\infty(K)}+2 \overline{C}(2R+1)M\,W_1(\mu_0^N,\mu_0)\Bigr)\nonumber\\
			&\qquad\times
				2R\Bigl(\|b_N-a\|_{L_\infty(K)}+\|b-a\|_{L_\infty(K)}\Bigr)\nonumber\\
			&\leq 8RM\Bigl(2R \| b_{N}-b\|_{L_\infty(K)}+2\overline{C}(2R+1)M\,W_1(\mu_0^N,\mu_0)\Bigr)
	\end{align}
	uniformly in $t \in [0,T]$ and $x \in B(0,R)$. A combination of \eqref{aux3} with \eqref{aux1} and
	\eqref{aux2} yields
	\begin{align*}
		|G_N(t)-G(t)|
			\leq 32\overline{C}R(2R+1)M^2 W_1(\mu_0^N,\mu_0)+16R^2M\| b_{N}-b\|_{L_\infty(K)}
	\end{align*}
	uniformly in $t \in [0,T]$. Thus we finally arrive at
	\begin{align*}
		\bigl|\mathcal E^{[a],N}(b_N)-\mathcal E^{[a]}(b)\bigr|
			&=\biggl|\frac{1}{T}\int^T_0\bigl(G_N(t)-G(t)\bigr)dt\biggr|\\
			&\leq 32\overline{C}R(2R+1)M^2 W_1(\mu_0^N,\mu_0)+16R^2M\| b_{N}-b\|_{L_\infty(K)}.
	\end{align*}
	This proves the claim.

\end{proof}









As a corollary, we now immediately obtain the following convergence result.

\begin{lemma}\label{lemma-semicontinuous-1}
	Under the assumptions of Theorem \ref{thm}, let $(b_N)_{N \in \N}\subset X_{M,K}$ be a sequence of continuous functions
	uniformly converging to a function $b \in X_{M,K}$ on $K=[0,2R]$  with $R>0$ as in \eqref{Rest}.
	Then it holds
	\begin{align*}
		\lim_{N\rightarrow\infty} \mathcal E^{[a],N}(b_{N})= \mathcal E^{[a]}(b).
	\end{align*}
\end{lemma}

\begin{proof}
	This follows immediately from the estimate \eqref{approxestimate}, upon noticing
	$\W_1(\mu_0,\mu^N_0) \rightarrow 0$ for $N \rightarrow \infty$ as a consequence of the Glivenko-Cantelli theorem,
see for instance \cite[Lemma 3.3]{fornahuetter}.
\end{proof}

\subsection{Proof of the main result}

We are now ready to present the proof of our main result Theorem \ref{thm}.


\begin{proof}[\normalfont\bf Proof of Theorem \ref{thm}]

	The sequence of minimizers $(\widehat a_N)_{N \in \N}$ is by definition a subset of $X_{M,K}$, hence by Proposition \ref{XMdef} it admits a subsequence $(\widehat a_{N_k})_{k \in \N}$ uniformly converging to a function $\widehat a \in X_{M,K}$.
	
	To show the optimality of $\widehat a$ in $X_{M,K}$, let $b\in X_{M,K}$ be given. By Definition \ref{VNdef}, we can find a sequence $(b_N)_{N \in \N}$ converging uniformly to $b$ on $K$ such that $b_N\in V_N$ for every $N\in \N$. Lemma \ref{lemma-semicontinuous-1} implies
	\begin{align*}
		\lim_{N\rightarrow\infty} \mathcal E^{[a],N}(b_{N})= \mathcal E^{[a]}(b),
	\end{align*}	
	and, by the optimality of $\widehat a_{N_k}$ in $V_N$, it follows that
	\begin{align*}
		\mathcal E^{[a]} (b)=\lim_{N\rightarrow\infty}\mathcal E^{[a],N}(b_N)
			= \lim_{k \rightarrow\infty}\mathcal E^{[a],N_k}(b_{N_k})
			\geq\lim_{k \rightarrow\infty}\mathcal E^{[a],N_k}(\widehat a_{N_k})
			= \mathcal E^{[a]} (\widehat a)\,.
	\end{align*}
	We can therefore conclude that for every $b \in X_{M,K}$
	\begin{align}\label{fond}
		 \mathcal E^{[a]} (b)\geq \mathcal E^{[a]} (\widehat a)\,.
	\end{align}
 In particular, \eqref{fond} applies to $b=a\in X_{M,K}$ (by the particular choice of $M$), which finally implies
	\begin{align*}
		0=\mathcal E^{[a]} (a)\geq \mathcal E^{[a]} (\widehat a)\geq 0\Longrightarrow \mathcal E^{[a]} (\widehat a)=0,
	\end{align*}
	showing that $\widehat a$ is also a minimizer of $\mathcal E^{[a]}$. When the coercivity condition \eqref{eq-coercive} holds,  it follows that $\widehat a=a$ in $L_2(\R_+,\rho)$.
Assume now that \eqref{rate1} and \eqref{rate2} hold together with  \eqref{eq-coercive}. Then, by these latter conditions, two applications of \eqref{approxestimate}, the minimality of $\widehat a_N$, and the optimality of
$a$ in the sense that $\mathcal E^{[a]}=0$, we obtain the following chain of estimates
\begin{eqnarray*}
\| \widehat a_N - a \|_{L_2(\R_+,\rho)}^2 &\leq& \frac{1}{c_T}  \mathcal E^{[a]}(\widehat a_N) \\
&\leq& \frac{1}{c_T} \left ( \mathcal E^{[a],N}(\widehat a_N) + ( \mathcal E^{[a]}(\widehat a_N)- \mathcal E^{[a],N}(\widehat a_N))  \right )\\
&\leq & \frac{1}{c_T} \left (\mathcal E^{[a],N}(\widehat a_N) +  c_1 \mathcal W_1(\mu_0^N,\mu_0) \right ) \\
&\leq &\frac{1}{c_T} \left (\mathcal E^{[a],N}(a_N) +  c_1 \mathcal W_1(\mu_0^N,\mu_0) \right ) \\
&\leq &\frac{1}{c_T} \left (2 c_1 \mathcal W_1(\mu_0^N,\mu_0) + c_2 \| a - a_N \|_{L_\infty(K)} \right ) \\
&\leq & C_3  N^{-\min \{\alpha,\beta\}}.
\end{eqnarray*} 
\MMcomment{I do not understand the last step...$a_N$ is not converging to $a$, the subsequence $a_{N_k}$ is...it seems to me that since we need to pass to a subsequence, we lose the rate. I hope I am mistaken. In fact if the proof is indeed correct, then it would actually show that $\hat a_N$ is converging to $a$, so we do not have to pass to subsequences, and so we can change even the statement of the Theorem to not talk about subsequences: that would be great.}
This concludes the proof.
\end{proof}