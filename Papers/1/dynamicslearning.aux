\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{AGS}
\citation{VCBCS95}
\citation{CucSma07}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}General abstract framework}{2}{subsection.1.1}}
\newlabel{gradientflow}{{1}{2}{General abstract framework}{equation.1.1}{}}
\citation{AGS}
\citation{cafotove10}
\citation{13-Carrillo-Choi-Hauray-MFL}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Example of gradient flow of nonlocal particle interactions}{3}{subsection.1.2}}
\newlabel{sec:gradflow}{{1.2}{3}{Example of gradient flow of nonlocal particle interactions}{subsection.1.2}{}}
\newlabel{fdgradientflow}{{2}{3}{Example of gradient flow of nonlocal particle interactions}{equation.1.2}{}}
\newlabel{intker}{{3}{3}{Example of gradient flow of nonlocal particle interactions}{equation.1.3}{}}
\newlabel{eq:meanfield}{{4}{3}{Example of gradient flow of nonlocal particle interactions}{equation.1.4}{}}
\citation{mann11}
\citation{heoemascszwa11}
\citation{brpi07}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Parametric energies and their identifications}{4}{subsection.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}The optimal control approach and its drawbacks}{4}{subsection.1.4}}
\newlabel{optcontr}{{5}{4}{The optimal control approach and its drawbacks}{equation.1.5}{}}
\newlabel{gradientflow2}{{6}{4}{The optimal control approach and its drawbacks}{equation.1.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}A variational approach towards learning parameter functions in nonlocal energies}{5}{subsection.1.5}}
\newlabel{sec:wp2}{{1.5}{5}{A variational approach towards learning parameter functions in nonlocal energies}{subsection.1.5}{}}
\newlabel{fdgradientflow2}{{7}{5}{A variational approach towards learning parameter functions in nonlocal energies}{equation.1.7}{}}
\newlabel{eq-def-error1}{{8}{5}{A variational approach towards learning parameter functions in nonlocal energies}{equation.1.8}{}}
\newlabel{trajapprox}{{1.1}{5}{}{theorem.1.1}{}}
\newlabel{eq:trajapprox}{{9}{5}{}{equation.1.9}{}}
\citation{MR1201152}
\newlabel{fdproxy}{{10}{6}{A variational approach towards learning parameter functions in nonlocal energies}{equation.1.10}{}}
\newlabel{pirlo}{{11}{6}{A variational approach towards learning parameter functions in nonlocal energies}{equation.1.11}{}}
\newlabel{ourfunctional}{{12}{6}{A variational approach towards learning parameter functions in nonlocal energies}{equation.1.12}{}}
\newlabel{est-functional-1}{{13}{6}{A variational approach towards learning parameter functions in nonlocal energies}{equation.1.13}{}}
\newlabel{midpoint1}{{14}{7}{A variational approach towards learning parameter functions in nonlocal energies}{equation.1.13}{}}
\newlabel{finallyrho}{{15}{7}{A variational approach towards learning parameter functions in nonlocal energies}{equation.1.15}{}}
\newlabel{rho}{{16}{7}{A variational approach towards learning parameter functions in nonlocal energies}{equation.1.16}{}}
\newlabel{midpoint2}{{17}{7}{A variational approach towards learning parameter functions in nonlocal energies}{equation.1.17}{}}
\newlabel{eq-coercive}{{18}{7}{A variational approach towards learning parameter functions in nonlocal energies}{equation.1.18}{}}
\newlabel{VNdef}{{1.2}{7}{}{theorem.1.2}{}}
\citation{bofohamaXX}
\citation{MR2249856}
\citation{MR2327596}
\newlabel{thm}{{1.3}{8}{}{theorem.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Numerical implementation of the variational approach }{8}{subsection.1.6}}
\newlabel{sec:wp3}{{1.6}{8}{Numerical implementation of the variational approach}{subsection.1.6}{}}
\citation{AGS}
\citation{villani}
\newlabel{finalestimate}{{19}{9}{Numerical implementation of the variational approach}{equation.1.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminaries}{9}{section.2}}
\newlabel{meanfield}{{2}{9}{Preliminaries}{section.2}{}}
\newlabel{e_Wp}{{20}{9}{Preliminaries}{equation.2.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The mean-field limit equation and existence of solutions}{10}{subsection.2.1}}
\newlabel{eq:contdyn}{{21}{10}{The mean-field limit equation and existence of solutions}{equation.2.21}{}}
\newlabel{eq:discrdyn}{{22}{10}{The mean-field limit equation and existence of solutions}{equation.2.22}{}}
\newlabel{eq:discr1}{{23}{10}{The mean-field limit equation and existence of solutions}{equation.2.23}{}}
\citation{AGS}
\citation{13-Carrillo-Choi-Hauray-MFL}
\newlabel{eq:empmeas}{{24}{11}{The mean-field limit equation and existence of solutions}{equation.2.24}{}}
\newlabel{pr:exist}{{2.2}{11}{}{theorem.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}The transport map and uniqueness of mean-field solutions}{11}{subsection.2.2}}
\newlabel{eq:transpdyn}{{25}{11}{The transport map and uniqueness of mean-field solutions}{equation.2.25}{}}
\citation{CanCarRos10}
\citation{CanCarRos10}
\newlabel{eq:fixedpoint}{{26}{12}{The transport map and uniqueness of mean-field solutions}{equation.2.26}{}}
\newlabel{p-transportlip}{{2.3}{12}{}{theorem.2.3}{}}
\newlabel{eq:liptrans}{{27}{12}{The transport map and uniqueness of mean-field solutions}{equation.2.27}{}}
\newlabel{uniq}{{2.4}{13}{}{theorem.2.4}{}}
\newlabel{supptot}{{28}{13}{}{equation.2.28}{}}
\newlabel{stab}{{29}{13}{}{equation.2.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}The learning problem for the kernel function}{13}{section.3}}
\newlabel{sec:learn}{{3}{13}{The learning problem for the kernel function}{section.3}{}}
\newlabel{eq-def-error}{{30}{13}{The learning problem for the kernel function}{equation.3.30}{}}
\citation{AFP00}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The measure $\overline  \rho $}{14}{subsection.3.1}}
\newlabel{rhosc}{{3.1}{14}{}{theorem.3.1}{}}
\newlabel{eq-rho-4}{{31}{14}{}{equation.3.31}{}}
\newlabel{lemma-AC-1}{{3.3}{15}{}{theorem.3.3}{}}
\newlabel{le-abs}{{3.4}{15}{}{theorem.3.4}{}}
\newlabel{rhocompact}{{3.5}{15}{}{theorem.3.5}{}}
\newlabel{eq:inftyimplyl2}{{32}{16}{The measure $\prerho $}{equation.3.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}On the coercivity assumption}{16}{subsection.3.2}}
\newlabel{sec:coerc}{{3.2}{16}{On the coercivity assumption}{subsection.3.2}{}}
\newlabel{eq-rho-3}{{33}{16}{On the coercivity assumption}{equation.3.33}{}}
\newlabel{uniquemin}{{3.6}{16}{}{theorem.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Coercivity is ``generically'' satisfied}{16}{subsubsection.3.2.1}}
\citation{Vershynin:NARMT}
\citation{Vershynin:NARMT}
\newlabel{e:coercivitydiscrete}{{34}{17}{Coercivity is ``generically'' satisfied}{equation.3.34}{}}
\newlabel{e:coermatrix}{{35}{17}{Coercivity is ``generically'' satisfied}{equation.3.35}{}}
\citation{AFP00}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Existence of minimizers of $\mathcal  E_N$}{18}{subsection.3.3}}
\newlabel{XMdef}{{3.7}{18}{}{theorem.3.7}{}}
\newlabel{ENmin}{{3.8}{18}{}{theorem.3.8}{}}
\newlabel{Faest}{{36}{18}{Existence of minimizers of $\mathcal E_N$}{equation.3.36}{}}
\citation{fornahuetter}
\@writefile{toc}{\contentsline {section}{\numberline {4}$\Gamma $-convergence of $\mathcal  E_N$ to $\mathcal  E$}{19}{section.4}}
\newlabel{lemma-semicontinuous-1}{{4.1}{19}{}{theorem.4.1}{}}
\newlabel{firstlim}{{37}{20}{$\Gamma $-convergence of $\mathcal E_N$ to $\mathcal E$}{equation.4.37}{}}
\newlabel{pippo3}{{38}{20}{$\Gamma $-convergence of $\mathcal E_N$ to $\mathcal E$}{equation.4.38}{}}
\newlabel{pippo1}{{39}{21}{$\Gamma $-convergence of $\mathcal E_N$ to $\mathcal E$}{equation.4.39}{}}
\newlabel{pippo2}{{40}{21}{$\Gamma $-convergence of $\mathcal E_N$ to $\mathcal E$}{equation.4.40}{}}
\newlabel{fond}{{41}{22}{$\Gamma $-convergence of $\mathcal E_N$ to $\mathcal E$}{equation.4.41}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Numerical experiments}{22}{section.5}}
\newlabel{sec:num}{{5}{22}{Numerical experiments}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Numerical framework}{22}{subsection.5.1}}
\newlabel{numfram}{{5.1}{22}{Numerical framework}{subsection.5.1}{}}
\newlabel{eq:knots}{{42}{23}{Numerical framework}{equation.5.42}{}}
\newlabel{problem2}{{43}{24}{Numerical framework}{equation.5.43}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Varying $N$}{24}{subsection.5.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Parameter values for Figure \ref  {variableN} and Figure \ref  {variableN2}}}{25}{table.1}}
\newlabel{tab:fig1}{{1}{25}{Parameter values for Figure \ref {variableN} and Figure \ref {variableN2}}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Iterative reconstruction of a potential with different values of $N$. In red: the unknown kernel. In blue: its reconstruction by minimization of $\mathcal  {E}_N$. From left-top to right-bottom: reconstruction with $N = 10$, $N = 20$, $N = 40$, $N = 80$ agents.}}{25}{figure.1}}
\newlabel{variableN}{{1}{25}{Iterative reconstruction of a potential with different values of $N$. In red: the unknown kernel. In blue: its reconstruction by minimization of $\mathcal {E}_N$. From left-top to right-bottom: reconstruction with $N = 10$, $N = 20$, $N = 40$, $N = 80$ agents}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}The coercivity constant}{25}{subsection.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Iterative reconstruction of a potential with a singularity at the origin and highly oscillatory behavior. In red: the unknown kernel. In blue: its reconstruction by minimization of $\mathcal  {E}_N$. From left-top to right-bottom: reconstruction with $N = 10$, $N = 20$, $N = 40$, $N = 80$ agents.}}{26}{figure.2}}
\newlabel{variableN2}{{2}{26}{Iterative reconstruction of a potential with a singularity at the origin and highly oscillatory behavior. In red: the unknown kernel. In blue: its reconstruction by minimization of $\mathcal {E}_N$. From left-top to right-bottom: reconstruction with $N = 10$, $N = 20$, $N = 40$, $N = 80$ agents}{figure.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Parameter values for Figure \ref  {errorN}}}{26}{table.2}}
\newlabel{tab:fig3}{{2}{26}{Parameter values for Figure \ref {errorN}}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Tuning the constraint $M$}{26}{subsection.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Plot of $\overline  {\mathcal  {E}}_N(\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle a$}\mathaccent "0362{a}_N)$ and $\frac  {1}{10}\delimiter "026B30D a-\setbox \z@ \hbox {\frozen@everymath \@emptytoks \mathsurround \z@ $\textstyle a$}\mathaccent "0362{a}_N\delimiter "026B30D ^2_{L_2(\mathbb  {R}_+,\rho )}$ for different values of $N$. In this experiment, we can estimate the constant $c_T$ with the value $\frac  {1}{10}$. {\color  {blue}{I would make this a $\qopname  \relax o{log}$ plot, i.e. with teh $y$-axis in $\qopname  \relax o{log}_{10}$ (or $\qopname  \relax o{log}_2$) scale}}}}{27}{figure.3}}
\newlabel{errorN}{{3}{27}{Plot of $\overline {\mathcal {E}}_N(\widehat {a}_N)$ and $\frac {1}{10}\|a-\widehat {a}_N\|^2_{L_2(\R _+,\rho )}$ for different values of $N$. In this experiment, we can estimate the constant $c_T$ with the value $\frac {1}{10}$. \MMcomment {I would make this a $\log $ plot, i.e. with teh $y$-axis in $\log _{10}$ (or $\log _2$) scale}}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Values of $\overline  {\mathcal  {E}}_N$ for fixed $N = 50$ for different values of $M \in [0,200]$.{\color  {blue}{I would make this a $\qopname  \relax o{log}$ plot, i.e. with teh $y$-axis in $\qopname  \relax o{log}_{10}$ (or $\qopname  \relax o{log}_2$) scale}}}}{27}{figure.4}}
\newlabel{Mconstr}{{4}{27}{Values of $\overline {\mathcal {E}}_N$ for fixed $N = 50$ for different values of $M \in [0,200]$.\MMcomment {I would make this a $\log $ plot, i.e. with teh $y$-axis in $\log _{10}$ (or $\log _2$) scale}}{figure.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Parameter values for Figure \ref  {Mconstr1}}}{27}{table.3}}
\newlabel{tab:figM}{{3}{27}{Parameter values for Figure \ref {Mconstr1}}{table.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Iterative reconstruction of a potential with different values of $M$. On the left column: the true kernel in white and its reconstructions for different $M$; the brighter the curve, the larger the $M$. On the right column: the true trajectories of the agents in white, the trajectories associated to the reconstructed potentials with the same color.{\color  {blue}{This pictures appear on gray/dark background when I compile, instead of white...}}}}{28}{figure.5}}
\newlabel{Mconstr1}{{5}{28}{Iterative reconstruction of a potential with different values of $M$. On the left column: the true kernel in white and its reconstructions for different $M$; the brighter the curve, the larger the $M$. On the right column: the true trajectories of the agents in white, the trajectories associated to the reconstructed potentials with the same color.\MMcomment {This pictures appear on gray/dark background when I compile, instead of white...}}{figure.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Parameter values for Figure \ref  {Mconstr}}}{28}{table.4}}
\newlabel{tab:fig4}{{4}{28}{Parameter values for Figure \ref {Mconstr}}{table.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Reconstruction with $N$ fixed}{28}{subsection.5.5}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Parameter values for Figure \ref  {fixedN}}}{29}{table.5}}
\newlabel{tab:fig5}{{5}{29}{Parameter values for Figure \ref {fixedN}}{table.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Reconstruction of $a$ obtained by averaging 5 solutions of the minimization of $\mathcal  {E}_N$ for $N = 50$. In red: the unknown kernel. In blue: the average of reconstructions. In black: 95\% confidence interval.}}{29}{figure.6}}
\newlabel{fixedN}{{6}{29}{Reconstruction of $a$ obtained by averaging 5 solutions of the minimization of $\mathcal {E}_N$ for $N = 50$. In red: the unknown kernel. In blue: the average of reconstructions. In black: 95\% confidence interval}{figure.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Appendix}{29}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Technical lemmas for the mean-field limit}{29}{subsection.6.1}}
\newlabel{ap1}{{6.1}{29}{Technical lemmas for the mean-field limit}{subsection.6.1}{}}
\citation{MFOC}
\newlabel{p-rewritten}{{6.1}{30}{}{theorem.6.1}{}}
\newlabel{p-estkernel}{{6.2}{30}{}{theorem.6.2}{}}
\newlabel{p-Floclip}{{6.3}{30}{}{theorem.6.3}{}}
\newlabel{p-Fmuloclip}{{6.4}{30}{}{theorem.6.4}{}}
\citation{MFOC}
\citation{CanCarRos10}
\newlabel{p-lipkernel}{{6.6}{31}{}{theorem.6.6}{}}
\newlabel{eq:bsupp}{{45}{31}{}{equation.6.45}{}}
\newlabel{eq:inftynormW1}{{46}{31}{}{equation.6.46}{}}
\citation{Kin-Sta}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Proof of Proposition \ref  {pr:exist}}{32}{subsection.6.2}}
\newlabel{ap2}{{6.2}{32}{Proof of Proposition \ref {pr:exist}}{subsection.6.2}{}}
\newlabel{Rest}{{47}{32}{Proof of Proposition \ref {pr:exist}}{equation.6.47}{}}
\citation{AGS}
\citation{KelleyTop}
\newlabel{eq:unifconv}{{48}{33}{Proof of Proposition \ref {pr:exist}}{equation.6.48}{}}
\citation{Fil}
\citation{Fil}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Existence and uniqueness of solutions for \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:transpdyn}\unskip \@@italiccorr )}}}{34}{subsection.6.3}}
\newlabel{ap3}{{6.3}{34}{Existence and uniqueness of solutions for \eqref {eq:transpdyn}}{subsection.6.3}{}}
\newlabel{cara}{{49}{34}{Existence and uniqueness of solutions for \eqref {eq:transpdyn}}{equation.6.49}{}}
\newlabel{cara-global}{{6.7}{34}{}{theorem.6.7}{}}
\newlabel{l1}{{50}{34}{}{equation.6.50}{}}
\newlabel{ttz}{{51}{34}{}{equation.6.51}{}}
\newlabel{gron}{{52}{34}{}{equation.6.52}{}}
\newlabel{le:uniquecara}{{6.8}{35}{}{theorem.6.8}{}}
\newlabel{gronvalla}{{53}{35}{}{equation.6.53}{}}
\citation{CanCarRos10}
\citation{CanCarRos10}
\newlabel{eq:uniquecara}{{54}{36}{Existence and uniqueness of solutions for \eqref {eq:transpdyn}}{equation.6.54}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Continuous dependence on the initial data}{36}{subsection.6.4}}
\newlabel{ap4}{{6.4}{36}{Continuous dependence on the initial data}{subsection.6.4}{}}
\newlabel{primstim}{{6.10}{36}{}{theorem.6.10}{}}
\bibstyle{abbrv}
\bibdata{biblio}
\bibcite{AFP00}{1}
\bibcite{AGS}{2}
\bibcite{MR2327596}{3}
\bibcite{MR2249856}{4}
\bibcite{bofohamaXX}{5}
\bibcite{brpi07}{6}
\newlabel{start}{{55}{37}{Continuous dependence on the initial data}{equation.6.55}{}}
\newlabel{stima2}{{56}{37}{Continuous dependence on the initial data}{equation.6.56}{}}
\bibcite{CanCarRos10}{7}
\bibcite{13-Carrillo-Choi-Hauray-MFL}{8}
\bibcite{cafotove10}{9}
\bibcite{CucSma07}{10}
\bibcite{MR1201152}{11}
\bibcite{Fil}{12}
\bibcite{fornahuetter}{13}
\bibcite{MFOC}{14}
\bibcite{heoemascszwa11}{15}
\bibcite{KelleyTop}{16}
\bibcite{Kin-Sta}{17}
\bibcite{mann11}{18}
\bibcite{Vershynin:NARMT}{19}
\bibcite{VCBCS95}{20}
\bibcite{villani}{21}
\@writefile{toc}{\contentsline {chapter}{biblio}{39}{section*.1}}
