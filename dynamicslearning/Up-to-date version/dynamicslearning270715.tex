\documentclass[A4paper,11pt]{article}
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{enumerate}
%\usepackage{enumitem}
\usepackage{paralist}
\usepackage{graphics} %% add this and next lines if pictures should be in esp format
\usepackage{float}
\usepackage{epsfig} %For pictures: screened artwork should be set up with an 85 or 100 line screen
\usepackage{graphicx}
\usepackage{epstopdf}%This is to transfer .eps figure to .pdf figure; please compile your paper using PDFLeTex or PDFTeXify.
%\usepackage[colorlinks=true]{hyperref}
%\hypersetup{urlcolor=blue, citecolor=red}
\usepackage{hyperref}
%\usepackage{refcheck}

\usepackage{bm}
\usepackage{color}

%  \textheight=8.2 true in
%   \textwidth=5.0 true in
%    \topmargin 30pt
%     \setcounter{page}{1}

\usepackage[a4paper]{geometry}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem*{main}{Main Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}{Conjecture}
\newtheorem*{problem}{Problem}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}
\newtheorem*{notation}{Notation}
\newtheorem{assumption}{Assumption}
\newcommand{\ep}{\varepsilon}
\newcommand{\eps}[1]{{#1}_{\varepsilon}}

\newcommand{\vnorm}[1]{\left\| #1 \right\|}
\newcommand{\scalarp}[1]{\left\langle #1 \right\rangle}
\newcommand{\redd}[1]{{\color{red}{#1}}}

\newcommand{\Lip}{\textup{Lip}}
\newcommand{\loc}{\textup{loc}}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\cb}{\mathcal{B}}
\newcommand{\cf}{\mathcal{F}}
\newcommand{\ch}{\mathcal{H}}
\newcommand{\cl}{\mathcal{L}}
\newcommand{\cn}{\mathcal{N}}
\newcommand{\ct}{\mathcal{T}}
\newcommand{\W}{\mathcal{W}}
\newcommand{\PP}{\mathcal{P}_1}
\newcommand{\PC}{\mathcal{P}_c}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\diam}{diam}
\DeclareMathOperator{\argmin}{arg\,min}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator*{\esssup}{ess\,sup}

\allowdisplaybreaks


\title{Interaction Kernel Learning in Multi-Agent Dynamical System}

\author{M. Bongini, M. Fornasier, M. Hansen, M. Maggioni}

\date{}

\begin{document}
\maketitle

\bigskip

\section{Introduction}

The continuity equation in physics describes the transport of a conserved quantity. Several quantities, such as mass, energy, momentum, electric charge and opinion (in social dynamics) are conserved, hence a variety of physical and social phenomena can be described using the continuity equation, which can be written in differential form as
\begin{align*}
\frac{\partial \mu}{\partial t} = -\nabla \cdot (H\mu).
\end{align*}
The function $H$ is the flow velocity vector field and determines the dynamics of the conserved quantity $\mu$.

Due to its ubiquity, it is very easy to find quantities whose evolution can be described by the continuity equation. Once such a quantity has been identified, a crucial problem is then to determine the correct form of the velocity field $H$, which highly depends on the particular quantity of interest $\mu$. As observers of the dynamics of $\mu$ (with which we are not allowed to interact), the exact determination of $H$ has to be done with the only information at our disposal, that is samples of the trajectory of $\mu$.

We are interested in addressing this problem in the context of \textit{convolution-type dynamics}, in which the velocity field has the specific form
\begin{align*}
H = F[a]*\mu,
\end{align*}
where $F[a](\xi) = a(|\xi|)\xi$ for any $\xi \in \R^d$ and $a:\R_+\rightarrow \R$. The function $a$ is called \textit{interaction kernel} and this form of the continuity equation is often encountered in biology, chemistry and social sciences (see \cite{CS,lennard24,reynolds1987flocks,vicsek2012collective}). The interaction kernel $a$ is then the function to be learned from the samples of the trajectories of $\mu$...

\section{Preliminaries}\label{meanfield}


The space $\mathcal{P}(\R^n)$ is the set of probability measures which take values on $\R^n$, while the space\footnote{We follow the notation of \cite{AGS}.} $\mathcal{P}_p(\R^n)$ is the subset of $\mathcal{P}(\R^n)$ whose elements have finite $p$-th moment, i.e.,
$$\int_{\R^n} |x|^p d\mu(x) < +\infty.$$
We denote by $\mathcal{P}_c(\R^n)$ the subset of $\mathcal{P}_1(\R^n)$ which consists of all probability measures with compact support. %Notice that, if $(\mu_{\ell})_{\ell \in \N}$ is a sequence in $\mathcal{P}_c(\R^n)$ and it exists $R>0$ such that $\supp(\mu_{\ell}) \subseteq B(0, R)$ for all $\ell\in\N$, then $(\mu_{\ell})_{\ell \in \N}$ is compact in $\mathcal{P}_p(\R^n)$ for all $p \geq 1$.

For any $\mu \in \mathcal{P}(\R^n)$ and any Borel function $f: \R^{n_1} \to \R^{n_2}$, we denote by $f_{\#}\mu \in \mathcal{P}(\R^{n_2})$ the {\it push-forward of $\mu$ through $f$}, defined by
\begin{align*}
f_{\#}\mu(B) := \mu(f^{-1}(B)) \quad \text{ for every Borel set } B \text{ of } \R^{n_2}.
\end{align*}
In particular, if one considers the projection operators $\pi_1$ and $\pi_2$ defined on the product space $\R^{n_1} \times \R^{n_2}$, for every $\rho \in \mathcal{P}(\R^{n_1} \times \R^{n_2})$ we call {\it first} (resp., {\it second}) {\it marginal} of $\rho$ the probability measure $\pi_{1\#}\rho$ (resp., $\pi_{2\#}\rho$). Given $\mu \in \mathcal{P}(\R^{n_1})$ and $\nu \in \mathcal{P}(\R^{n_2})$, we denote with $\Gamma(\mu, \nu)$ the subset of all probability measures in $\mathcal{P}(\R^{n_1} \times \R^{n_2})$ with first marginal $\mu$ and second marginal $\nu$.

On the set $\mathcal{P}_p(\R^n)$ we shall consider the following distance, called the {\it Wasserstein or Monge-Kantorovich-Rubinstein distance},
\begin{align}  \label{e_Wp}
\W^p_p(\mu,\nu)=\inf \left \{ \int_{\R^{2n}} |x-y|^p d \rho(x,y) : \rho \in \Gamma(\mu,\nu) \right \}.
\end{align}
If $p = 1$, we have the following equivalent expression for the Wasserstein distance:
\begin{align*}
\W_1(\mu,\nu)=\sup \left \{ \int_{\R^n} \varphi(x) d (\mu-\nu)(x)  : \varphi \in \Lip(\R^n), \; \Lip_{\R^n}(\varphi) \leq 1 \right \},
\end{align*}
where $\Lip_{\R^n}(\varphi)$ stands for the Lipschitz constant of $\varphi$ on $\R^n$. We denote by $\Gamma_o(\mu,\nu)$ the set of optimal plans for which the minimum is attained, i.e.,
\begin{align*}
\rho \in \Gamma_o(\mu, \nu) \iff \rho \in \Gamma(\mu, \nu) \text{ and } \int_{\R^{2n}} | x - y |^p d \rho(x,y) = \W^p_p(\mu,\nu).
\end{align*}
It is well-known that $\Gamma_o(\mu, \nu)$ is non-empty for every $(\mu,\nu) \in \mathcal{P}_p(\R^n)\times\mathcal{P}_p(\R^n)$, hence the infimum in \eqref{e_Wp} is actually a minimum. For more details, see e.g. \cite{AGS,villani}.

For any $\mu \in \PP(\R^d)$ and $f: \R^d \to \R^d$, the notation $f * \mu$ stands for the convolution of $f$ and $\mu$, i.e.,
\begin{align*}
(f * \mu)(x) = \int_{\R^d} f(x - x') d\mu(x');
\end{align*}
this quantity is well-defined whenever $f$ is continuous and \emph{sublinear}, i.e., there exists a constant $C > 0$ such that $| f(\xi) | \leq C (1 + |\xi|)$ for all $\xi \in \R^d$.

\subsection{The mean-field limit and an existence result}

As already stated in the introduction, we are interested in the following \textit{finite time horizon initial value problem}: given $T > 0$ and $\mu_0 \in \PC(\R^d)$, consider a curve $\mu:[0,T]\rightarrow \PP(\R^d)$ satisfying
\begin{align}\label{eq:contdyn}
\left\{\begin{aligned}
\frac{\partial \mu}{\partial t}(t) &= -\nabla \cdot ((F[a]*\mu(t))\mu(t)) \quad \text{ for } t \in (0,T],\\
\mu(0) &=\mu_0.
\end{aligned}\right.
\end{align}
We consequently give our notion of solution for \eqref{eq:contdyn}.

\begin{definition}
We say that a map $\mu:[0,T]\rightarrow\PP(\R^d)$ is a solution of \eqref{eq:contdyn} with initial datum $\mu_0$ if the following hold:
\begin{enumerate}
\item $\mu$ has uniformly compact support, i.e., there exists $R > 0$ such that $\supp(\mu(t)) \subset B(0,R)$ for every $t \in [0,T]$;
\item $\mu$ is continuous with respect to the Wasserstein distance $\W_1$;
\item $\mu$ satisfies \eqref{eq:contdyn} in the weak sense, i.e., for every $\phi \in \mathcal{C}^{\infty}_c(\R^d;\R)$ it holds
\begin{align*}
\frac{d}{dt} \int_{\R^d} \phi(x) d\mu(t)(x) = \int_{\R^d} \nabla \phi(x) \cdot (F[a]*\mu(t))(x) d\mu(t)(x).
\end{align*}
\end{enumerate}
\end{definition}

It is well known that system \eqref{eq:contdyn} is closely related to the family of ODEs indexed by $N \in \N$ given by
\begin{align}\label{eq:discrdyn}
\left\{\begin{aligned}
\dot{x}^N_i(t) &= \frac{1}{N}\sum^N_{j = 1}F[a](x^N_i(t) - x^N_j(t)) \quad \text{ for } t \in (0,T],\\
x_i^N(0) &= x^N_{0,i},
\end{aligned} \quad i = 1, \ldots, N, \right.
\end{align}
which can be more conveniently rewritten as follows
\begin{align}\label{eq:discr1}
\left\{\begin{aligned}
\dot{x}^N_i(t) &= (F[a]*\mu^N(t))(x^N_i(t)) \quad \text{ for } t \in (0,T],\\
x^N_i(0) &= x^N_{0,i},
\end{aligned} \quad i = 1, \ldots, N, \right.
\end{align}
by means of the \textit{empirical measure} $\mu^N:[0,T]\rightarrow\PC(\R^d)$ defined as
\begin{align}\label{eq:empmeas}
\mu^N(t)(x) = \frac{1}{N}\sum^N_{i = 1} \delta(x - x^N_i(t)), \quad \text{ for every } x \in \R^d.
\end{align}


The following preliminary result tells us that solutions to system \eqref{eq:discrdyn} are also solutions to systems \eqref{eq:contdyn}, whenever conveniently rewritten.

\begin{proposition}\label{p-rewritten}
Let $N \in \N$ be given. Let $(x^N_1, \ldots, x^N_N):[0,T] \rightarrow \R^{dN}$ be the solution of \eqref{eq:discrdyn} with initial datum $x^{N}_0 \in \R^{dN}$. Then the empirical measure $\mu^N:[0,T] \rightarrow \PP(\R^d)$ defined as in \eqref{eq:empmeas} is a solution of \eqref{eq:contdyn} with initial datum $\mu^{N}_0 := \mu^N(0) \in \PC(\R^d)$.
\end{proposition}
\begin{proof}
It can be easily proved by arguing exactly as in \cite[Lemma 4.3]{MFOC}.
\end{proof}

The well-posedness of system \eqref{eq:contdyn} and several crucial properties that it enjoys can be proved as soon as we restrict our attention to interaction kernels belonging to the following \textit{set of admissible kernels}
\begin{align*}
	X=\bigl\{b:\R_+\rightarrow\R\,|\ b \in L^{\infty}(\R_+) \cap W^{1,\infty}_\loc(\R_+) \bigr \}.
\end{align*}
Notice that, if $a \in X$ then it is weakly differentiable and for every compact set $K \subset \R_+$ its local Lipschitz constant $\Lip_{K}(a)$ is finite. As a consequence, we are able to state several basic estimates that shall be useful towards an existence and uniqueness result for the solutions of system \eqref{eq:discrdyn}.

\begin{lemma}\label{p-estkernel}
Let $a\in X$ and $\mu \in \PP(\R^d)$. Then for all $y \in \R^d$ the following hold:
\begin{align*}
|(F[a] * \mu)(y)| \leq \|a\|_{L^{\infty}(\R_+)}\left( | y | + \int_{\R^d} | x | d\mu(x) \right).
\end{align*}
\end{lemma}
\begin{proof}
Trivially follows from $a \in L^{\infty}(\R_+)$.
\end{proof}

\begin{lemma}\label{p-Floclip}
If $a\in X$ then $F[a] \in \Lip_\loc(\R^d)$.
\end{lemma}
\begin{proof}
For any compact set $K \subset \R^d$ and for every $x,y \in K$ it holds
\begin{align*}
|F[a](x) - F[a](y)| &= |a(|x|)x - a(|y|)y| \\
&\leq |a(|x|)| |x-y| + |a(|x|) - a(|y|)| |y| \\
&\leq (|a(|x|)| + \Lip_K(a) |y|) |x-y|,
\end{align*}
and since $a \in L^{\infty}(\R_+)$ and $y \in K$, it follows that $F[a]$ is locally Lipschitz with Lipschitz constant depending only on $a$ and $K$.
\end{proof}

\begin{lemma}\label{p-Fmuloclip}
If $a\in X$ and $\mu \in \mathcal{P}_c(\R^d)$ then $F[a]*\mu \in \Lip_{\loc}(\R^d)$.
\end{lemma}
\begin{proof}
For any compact set $K \subset \R^d$ and for every $x,y \in K$ it holds
\begin{align*}
|(F[a]*\mu)(x) - (F[a]*\mu)(y)| &= \left|\int_{\R^d}a(|x-z|)(x-z)d\mu(z) - \int_{\R^d}a(|y-z|)(y-z)d\mu(z)\right| \\
&\leq \int_{\R^d}|a(|x-z|)-a(|y-z|)|x-z|d\mu(z)\\
&\quad+ \int_{\R^d}a(|y-z|)|x-y|d\mu(z) \\
&\leq \Lip_{\widehat{K}}(a)|x-y| \int_{\R^d}|x-z|d\mu(z) + \|a\|_{L^{\infty}(\R_+)}|x-y| \\
&\leq \left(\Lip_{\widehat{K}}(a)(|x| + 1)+ \|a\|_{L^{\infty}(\R_+)}\right)|x-y| \\
& \leq \left(C\Lip_{\widehat{K}}(a) + \|a\|_{L^{\infty}(\R_+)} \right)|x-y|,
\end{align*}
where $C$ is a constant depending on $K$, and $\widehat{K}$ is a compact set containing both $K$ and $\supp(\mu)$.
\end{proof}

\begin{proposition}
If $a \in X$ then system \eqref{eq:discrdyn} admits a unique global solution in $[0,T]$ for every initial datum $x^{N}_0 \in \R^{dN}$.
\end{proposition}
\begin{proof}
Rewriting system \eqref{eq:discrdyn} in the form of \eqref{eq:discr1}, from Lemma \ref{p-Fmuloclip} follows trivially that the function $G:\R^{dN} \rightarrow \R^{dN}$ defined for every $(x_1, \ldots, x_N)\in \R^{dN}$ as
\begin{align*}
G(x_1, \ldots, x_N) = ((F[a]*\mu^N)(x_1),\ldots,(F[a]*\mu^N)(x_N)),
\end{align*}
where $\mu^N$ is the empirical measure given by \eqref{eq:empmeas}, satisfies $G \in \Lip_\loc(\R^{dN})$. The Cauchy-Lipschitz Theorem for ODE systems then yields the desired result.
\end{proof}

Variants of the following result are \cite[Lemma 6.7]{MFOC} and \cite[Lemma 4.7]{CanCarRos10}

\begin{lemma}\label{p-lipkernel}
Let $a \in X$ and let $\mu:[0,T] \rightarrow \mathcal{P}_c(\R^d)$ and $\nu: [0,T] \to \PP(\R^d)$ be two continuous maps with respect to $\W_1$ satisfying
\begin{align}\label{eq:bsupp}
\supp(\mu(t)) \cup \supp(\nu(t)) \subseteq B(0,R),
\end{align}
for every $t \in [0,T]$, for some $R > 0$. Then for every $r > 0$ there exists a constant $L_{a,r,R}$ such that
\begin{align}\label{eq:inftynormW1}
\|F[a] * \mu(t) - F[a] * \nu(t)\|_{L^{\infty}(B(0,r))} \leq L_{a,r,R} \W_1(\mu(t),\nu(t))
\end{align}
for every $t \in [0,T]$.
\end{lemma}
\begin{proof}
Fix $t \in [0,T]$ and take $\pi \in \Gamma_o(\mu(t),\nu(t))$. Since the marginals of $\pi$ are by definition $\mu(t)$ and $\nu(t)$, it follows
\begin{align*}
F[a] * \mu(t)(x) - F[a] * \nu(t)(x) &= \int_{B(0,R)} F[a](x-y) d\mu(t)(y) - \int_{B(0,R)} F[a](x-z) d\nu(t)(z)  \\
&= \int_{B(0,R)^2} \left(F[a](x-y) - F[a](x-z)\right) d\pi(y,z)
\end{align*}
By using Lemma \ref{p-Floclip} and the hypothesis \eqref{eq:bsupp}, we have
\begin{align*}
\|F[a] * \mu(t) - F[a] * \nu(t)\|_{L^{\infty}(B(0,r))} &\leq \esssup_{x \in B(0,r)} \int_{B(0,R)^2} \left|F[a](x-y) - F[a](x-z)\right| d\pi(y,z) \\
&\leq \Lip_{B(0,R+r)}(F[a]) \int_{B(0,R)^2} |y - z| d\pi(y,z) \\
&= \Lip_{B(0,R+r)}(F[a]) \W_1(\mu(t),\nu(t)),
\end{align*}
hence \eqref{eq:inftynormW1} holds with $L_{a,r,R} = \Lip_{B(0,R+r)}(F[a])$.
\end{proof}

The following result provides a strong link between solutions of system \eqref{eq:discrdyn} and those of system \eqref{eq:contdyn}, one that in the end enables us to state an existence result for the latter ones. 

\begin{proposition}\label{pr:exist}
Let $\mu_0 \in \PC(\R^d)$ be given. Let $(\mu^{N}_0)_{N \in \N} \subset \PC(\R^d)$ be a sequence of empirical measures of the form
\begin{align*}
\mu^{N}_0(x) = \frac{1}{N}\sum^N_{i = 1} \delta(x - x^{N}_{0,i}), \quad \text{ for some } x^{N}_{0,i} \in \supp(\mu_0) + \overline{B(0,1)}
\end{align*}
satisfying $\lim_{N \rightarrow \infty} \W_1(\mu_0,\mu^{N}_0) = 0$. For every $N \in \N$, denote with $\mu^N:[0,T] \rightarrow \PP(\R^{d})$ the curve given by \eqref{eq:empmeas} where $(x^N_1,\ldots,x^N_N)$ is the unique solution of system \eqref{eq:discrdyn}.

Then, the sequence $(\mu^N)_{N \in \N}$ converges, up to subsequences, to a solution $\mu$ of \eqref{eq:contdyn} with initial datum $\mu_0$. Moreover, there exists $R > 0$ depending only on $T,a$, and $\supp(\mu_0)$ such that it holds
\begin{align*}
\supp(\mu^N(t)) \cup \supp(\mu(t)) \subseteq B(0,R), \quad \text{ for every } N \in \N \text{ and } t \in [0,T].
\end{align*}
\end{proposition}
\begin{proof}
Notice that for every $N \in \N$, by Proposition \ref{p-rewritten}, $\mu^N$ is the unique solution of \eqref{eq:contdyn} with initial datum $\mu^N_0$. We start by fixing $N \in \N$ and estimating the growth of $|x_i^N(t)|^2$ for $i = 1, \ldots, N$. By using Lemma \ref{p-estkernel}, we have
\begin{align*}
\frac{1}{2}\frac{d}{dt} |x_i^N(t)|^2 & \leq \dot{x}_i^N(t) \cdot x_i^N(t) \\
& \leq \left|(F[a]*\mu^N(t))(x_i(t))\right| |x_i^N(t)| \\
& \leq \|a\|_{L^{\infty}(\R_+)}\left( |x_i^N(t)| + \frac{1}{N} \sum^N_{j = 1}|x_j^N(t)| \right) |x_i^N(t)| \\
& \leq 2 \|a\|_{L^{\infty}(\R_+)}\max_{j = 1, \ldots, N} |x_j^N(t)| |x_i^N(t)| \\
& \leq 2 \|a\|_{L^{\infty}(\R_+)}\max_{j = 1, \ldots, N} |x_j^N(t)|^2.
\end{align*}
If we denote by $q(t) := \max_{j = 1, \ldots, N} |x_j^N(t)|^2$, then the Lipschitz continuity of $q$ implies that $q$ is a.e. differentiable. Stampacchia's Lemma \cite[Chapter 2, Lemma A.4]{Kin-Sta} ensures that for a.e. $t \in [0,T]$ there exists $k = 1, \ldots, N$ such that
\begin{align*}
\dot{q}(t) = \frac{d}{dt} |x_k^N(t)|^2 \leq 4 \|a\|_{L^{\infty}(\R_+)} q(t).
\end{align*}
Hence, Gronwall's Lemma and the hypothesis $x^{N}_{0,i} \in \supp(\mu_0) + \overline{B(0,1)}$ for every $N \in \N$ and $i = 1, \ldots, N$, imply that
\begin{align*}
q(t) \leq q(0) e^{4 \|a\|_{L^{\infty}(\R_+)} t} \leq C_0 e^{4 \|a\|_{L^{\infty}(\R_+)} t} \text{ for a.e. } t \in [0,T],
\end{align*}
for some uniform constant $C_0$ depending only on $\mu_0$. Therefore, the trajectory $\mu^N(\cdot)$ is bounded uniformly in $N$ in a ball $B(0,R) \subset \R^d$, where
\begin{align}\label{Rest}
R =  \sqrt{C_0} e^{2 \|a\|_{L^{\infty}(\R_+)} T}.
\end{align}
This, in turn, implies that $\mu^N(\cdot)$ is Lipschitz continuous with Lipschitz constant uniform in $N$, since by the fact that $|x^N_i(t)| \leq R$ for a.e. $t \in [0,T]$, for all $N \in N$ and $i = 1, \ldots, N$, and Lemma \ref{p-estkernel} follows
\begin{align*}
|\dot{x}^N_i(t)| &= |(F[a]*\mu^N(t))(x^N_i(t))| \\
&\leq \|a\|_{L^{\infty}(\R_+)} \left( |x^N_i(t)| + \frac{1}{N}\sum^N_{j = 1}|x^N_j(t)|\right) \\
&\leq 2R\|a\|_{L^{\infty}(\R_+)}.
\end{align*}
We have thus found a sequence $(\mu^N)_{N \in \N} \subset \mathcal{C}^0([0,T],\mathcal{P}_1(B(0,R)))$ for which the following holds:
\begin{itemize}
\item $(\mu^N)_{N \in \N}$ is equicontinuous and closed, because of the uniform Lipschitz constant $2R\|a\|_{L^{\infty}(\R_+)}$;
\item for every $t \in [0,T]$, the sequence $(\mu^N(t))_{N \in \N}$ is relatively compact in $\mathcal{P}_1(B(0,R))$. This holds because $(\mu^N(t))_{N \in \N}$ is a tight sequence, since $B(0,R)$ is compact, and hence relatively compact due to Prokhorov's Theorem.
\end{itemize}
Therefore, we can apply the Ascoli-Arzel\'{a} Theorem for functions with values in a metric space (see for instance, \cite[Chapter 7, Theorem 18]{KelleyTop}) to infer the existence of a subsequence $(\mu^{N_k})_{k \in \N}$ of $(\mu^N)_{N \in \N}$ such that
\begin{align}\label{eq:unifconv}
\lim_{k \rightarrow \infty}\W_1(\mu^{N_k}(t),\mu(t)) = 0 \quad \text{ uniformly for a.e. } t \in [0,T],
\end{align}
for some $\mu \in \mathcal{C}^0([0,T],\mathcal{P}_1(B(0,R)))$ with Lipschitz constant bounded by $2R\|a\|_{L^{\infty}(\R_+)}$. The hypothesis $\lim_{N\rightarrow\infty}\W_1(\mu^N_0,\mu_0) = 0$ now obviously implies $\mu(0) = \mu_0$.

We are now left with verifying that this curve $\mu$ is a solution of \eqref{eq:contdyn}. For all $t \in [0,T]$ and for all $\varphi \in \mathcal{C}^1_c(\R^d;\R)$, since it holds
\begin{align*}
\frac{d}{dt}\langle \varphi, \mu^N(t) \rangle = \frac{1}{N}\frac{d}{dt} \sum^N_{i = 1} \varphi(x^N_i(t)) = \frac{1}{N} \sum^N_{i = 1} \nabla\varphi(x^N_i(t)) \cdot \dot{x}_i^N(t),
\end{align*}
by directly applying the substitution $\dot{x}_i^N(t) = (F[a]*\mu^N(t))(x^N_i(t))$, we have
\begin{align*}
\langle \varphi, \mu^N(t) - \mu^N(0) \rangle = \int^t_0 \left[ \int_{\R^d}\nabla \varphi(x) \cdot (F[a]*\mu^N(s))(x) d\mu^N(s)(x) \right] ds.
\end{align*}
By Lemma \ref{p-lipkernel}, the inequality \eqref{eq:unifconv}, and the compact support of $\varphi \in \mathcal{C}^1_c(\R^d;\R)$, follows
\begin{align*}
\lim_{N \rightarrow \infty} \|\nabla\varphi \cdot (F[a]*\mu^N(t) - F[a]*\mu(t))\|_{L^{\infty}(\R^d)} = 0 \quad \text{ uniformly for a.e. } t \in [0,T].
\end{align*}
If we denote with $\mathcal L^1\llcorner_{[0,t]}$ the Lebesgue measure on the time interval $[0,t]$, since the product measures $\frac{1}{t} \mu^{N}(s) \times \mathcal L^1\llcorner_{[0,t]}$ converge in $\mathcal P_1([0,t] \times \mathbb R^{d})$ to $\frac{1}{t} \mu(s) \times \mathcal L^1\llcorner_{[0,t]}$, we finally get from the dominated convergence theorem that
\begin{align*}
\lim_{N \to \infty} \int_0^{t} \int_{\mathbb R^{d}} \nabla \phi(x) \cdot (F[a]*&\mu^N(s))(x) d\mu^N(s)(x) ds \\
&=  \int_0^{t} \int_{\mathbb R^{d}} \nabla \phi(x) \cdot (F[a]*\mu(s))(x) d \mu(s)(x) ds,
\end{align*}
which proves that $\mu$ is a solution of \eqref{eq:contdyn} with initial datum $\mu_0$.
\end{proof}

\subsection{The transport map and a uniqueness result}

Another way for building a solution of system \eqref{eq:contdyn} is by means of the so-called \textit{transport map}, i.e., the function describing the evolution in time of the initial measure $\mu_0$. The transport map can be constructed by considering the following one-agent version of system \eqref{eq:discr1},
\begin{align}\label{eq:transpdyn}
\left\{\begin{aligned}
\dot{\xi}(t) &= (F[a]*\mu(t))(\xi(t)) \quad \text{ for } t \in (0,T],\\
\xi(0) &= \xi_0,
\end{aligned}\right.
\end{align}
where $\xi$ is a mapping from $[0,T]$ to $\R^d$ and $a \in X$. Here $\mu:[0,T]\rightarrow\PP(\R^d)$ is a continuous map with respect to the Wasserstein distance $\W_1$ satisfying $\mu(0) = \mu_0$ and $\supp(\mu(t)) \subseteq B(0,R)$, where $R$ is given by \eqref{Rest} from the choice of $T$, $a$ and $\mu_0$.

For the reader's convenience we start by briefly recalling some general, well-known results about solutions to Carath{\'e}odory differential equations. We fix a domain $\Omega \subset \R^d$, a Carath{\'e}odory function $g\colon[0,T]\times \Omega \to \R^d$, and $0<\tau \le T$. A function $y\colon [0,\tau]\to \Omega$ is called a solution of the Carath{\'e}odory differential equation
\begin{equation}\label{cara}
\dot y(t)=g(t, y(t))
\end{equation}
on $[0,\tau]$ if and only if $y$ is absolutely continuous and \eqref{cara} is satisfied a.e.\ in $[0,\tau]$.
The following existence result holds.
%\begin{theorem}\label{cara2}
%Consider an interval $[0,T]$ on the real line and a domain $\Omega \subset \R^n$, for $n\ge 1$. Let $g\colon[0,T]\times \Omega \to \R^n$ be a Carath{\'e}odory function for which there exists a function $m \in L^1((0,T))$ such that
%$$
%|g(t,y)|\le m(t)
%$$
%for a.e.\ $t \in [0,T]$ and every $y \in \Omega$. Then, given $y_0 \in \Omega$, there exists $0<\tau \le T$ and a solution $y(t)$ of \eqref{cara} on $[0,\tau]$ satisfying $y(0)=y_0$. 
%
%If in addition there exists a function $l \in L^1((0,T))$ such that
%\begin{equation}\label{cara3}
%|g(t,y_1)-g(t, y_2)|\le l(t)|y_1-y_2|
%\end{equation}
%for a.e.\ $t \in [0,T]$ and every $y_1$, $y_2 \in \Omega$, the solution is uniquely determined on $[0,\tau]$ by the initial condition $y_0$.
%\end{theorem}
%
%\begin{proof}
%See, for instance, \cite[Chapter 1, Theorems 1 and 2]{Fil}.
%\end{proof}
%
%What follows is a generalization of the global existence theorem and of a Gronwall-type estimate on the solutions to this setting.

\begin{theorem}\label{cara-global}
Fix $T > 0$ and $y_0 \in \R^d$. Suppose that there exists a compact subset $\Omega$ of $\R^d$ such that $y_0 \in \textup{int}(\Omega)$ and there exists $m_{\Omega} \in L^1([0,T])$ for which it holds
%Consider an interval $[0,T]$ on the real line, a compact subset $K$ of $\R^n$, and a Carath{\'e}odory function $g\colon[0,T]\times \R^n \to \R^n$. If there exists a function $m \in L^1((0,T))$ such that
\begin{align}\label{l1}
|g(t,y)|\le m_{\Omega}(t),
\end{align}
for a.e.\ $t \in [0,T]$ and for all $y \in \Omega$. Then there exists a $\tau > 0$ and a solution $y(t)$ of \eqref{cara} defined on the interval $[0,\tau]$ which satisfies $y(0)=y_0$. If there exists $C > 0$ such that the function $g$ also satisfies the condition
\begin{align}\label{ttz}
|g(t,y)|\le C(1+|y|),
\end{align}
for a.e.\ $t \in [0,T]$ and every $y \in \Omega$, and it holds $B(0,R) \subseteq \Omega$, for $R > |y_0| + CT e^{CT}$, then the local solution $y(t)$ of \eqref{cara} which satisfies $y(0)=y_0$ can be extended to the whole interval $[0,T]$. Moreover, for every $t \in [0,T]$, any solution satisfies
\begin{equation}\label{gron}
|y(t)|\le \Big(|y_0|+ Ct\Big) \,e^{Ct}.
\end{equation}
%If in addition, for every relatively compact open subset $\Omega \subset \R^d$ there exists a constant $L_{\Omega}$ for which it holds
%\begin{align}\label{cara3}
%|g(t,y_1)-g(t, y_2)|\le L_{\Omega}|y_1-y_2|,
%\end{align}
%for a.e.\ $t \in [0,T]$ and every $y_1$, $y_2 \in \Omega$, then the solution is uniquely determined on $[0,T]$ by the initial condition $y_0$.
\end{theorem}

\begin{proof}
%Set $\rho:= (|y_0|+CT) \,e^{CT}$ and
Since $y_0 \in \textup{int}(\Omega)$, we can consider a ball $B(y_0,r) \subset \Omega$. The classical result \cite[Chapter 1, Theorem 1]{Fil} and \eqref{l1} yield the existence of a local solution defined on an interval $[0,\tau]$ and taking values in $B(y_0,r)$.

If \eqref{ttz} holds, any solution of \eqref{cara} with initial datum $y_0$ satisfies
$$
|y(t)|\le |y_0|+ Ct+C\int_0^t |y(s)|\,ds
$$
for every $t \in [0,\tau]$, therefore \eqref{gron} follows from Gronwall's inequality. In particular the graph of a solution $y(t)$ cannot reach the boundary of $[0,T]\times B(0,|y_0|+CTe^{CT})$ unless $\tau=T$, therefore the continuation of the local solution to a global one on $[0,T]$ follows, for instance, from \cite[Chapter 1, Theorem 4]{Fil}.
%Finally, if \eqref{cara3} holds, uniqueness of the global solution follows from \cite[Chapter 1, Theorem 2]{Fil}.
\end{proof}

Gronwall's inequality easily gives us the following results on continuous dependence on the initial data.

\begin{lemma}\label{le:uniquecara}
Let $g_1$ and $g_2\colon[0,T]\times \R^n \to \R^n$ be Carath{\'e}odory functions both satisfying \eqref{ttz} for the same  constant $C > 0$. Let $r>0$ and define 
\begin{align*}
\rho_{r, C, T}:=\Big(r+ CT\Big) \,e^{CT}\,.
\end{align*}
Assume in addition that there exists a constant $L > 0$ satisfying
\begin{align*}
|g_1(t, y_1)-g_1(t, y_2)|\le L|y_1-y_2|
\end{align*}
for every $t \in [0, T]$ and every $y_1$, $y_2$ such that $|y_i|\le \rho_{r, C, T}$, $i=1,2$.
Then, if $\dot y_1(t)=g_1(t, y_1(t))$, $\dot y_2(t)=g_2(t, y_2(t))$, $|y_1(0)|\le r$ and $|y_2(0)|\le r$, one has
\begin{equation}\label{gronvalla}
|y_1(t)-y_2(t)|\le e^{Lt}\left(|y_1(0)-y_2(0)|+\int_0^t \|g_1(s, \cdot)-g_2(s, \cdot)\|_{L^\infty(B(0, \rho_{r, C, T}))} \,ds \right)
\end{equation}
for every $t \in [0, T]$.
\end{lemma}
\begin{proof}
We can bound $|y_1(t) - y_2(t)|$ from above as follows:
\begin{align*}
|y_1(t) - y_2(t)| &\leq |y_1(0) - y_2(0)| + \int^t_0 |\dot{y}_1(s) - \dot{y}_2(s)| ds \\
&= |y_1(0) - y_2(0)| \\
& \quad + \int^t_0 |g_1(s, y_1(s)) - g_1(s, y_2(s)) + g_1(s, y_2(s)) - g_2(s, y_2(s))| ds \\
& \leq |y_1(0) - y_2(0)| + \int_0^t \|g_1(s, \cdot)-g_2(s, \cdot)\|_{L^\infty(B(0, \rho_{r, C, T}))} \,ds \\
& \quad  + L \int^t_0|y_1(s) - y_2(s)| ds.
\end{align*}
Since the function $\alpha(t) = |y_1(0) - y_2(0)| + \int_0^t \|g_1(s, \cdot)-g_2(s, \cdot)\|_{L^\infty(B(0, \rho_{r, C, T}))} \,ds$ is increasing, an application of Gronwall's inequality gives \eqref{gronvalla}, as desired.
\end{proof}


\begin{proposition}
Fix $T > 0$, $a \in X$, $\mu_0 \in \mathcal{P}_c(\R^d)$, $\xi_0 \in \R^d$ and let $R > 0$ be given by Proposition \ref{pr:exist} from the choice of $T, a$ and $\mu_0$. For every map $\mu:[0,T] \rightarrow \PP(\R^d)$ which is continuous with respect to $\W_1$ such that
\begin{align*}
\supp(\mu(t)) \subseteq B(0,R) \quad \text{ for every } t \in [0,T],
\end{align*}
there exists a unique solution of system \eqref{eq:transpdyn} with initial value $\mu_0$ defined on the whole interval $[0,T]$.
\end{proposition}
\begin{proof}
By Lemma \ref{p-estkernel} follows that, for any compact set $K \subset \R^d$ containing $\xi_0$, there exists a function $m_K \in L^1([0,T])$ for which the function $g(t,y)=(F[a]\ast\mu(t))(y)$ satisfies \eqref{l1}. Moreover, for fixed $t$ this function is locally Lipschitz continuous, as follows from Lemma \ref{p-Fmuloclip}, thus $g(t,y)=(F[a]\ast\mu(t))(y)$ is a Carath\'eodory function.

%Notice that $a \in L^{\infty}(\R_+)$ trivially implies that of $F[a] \in L^{\infty}_{\loc}(\R^d)$. This, together with Lemma \ref{p-estkernel} and the hypothesis that $\supp(\mu(t)) \subseteq B(0,R)$ for all $t \in [0,T]$, yields $F[a]\ast\mu(t)\in L^{\infty}(\R_+)$ uniformly in $t$, hence \eqref{l1} holds. 
		
From the hypothesis that the support of $\mu$ is contained in $B(0,R)$ and Lemma \ref{p-estkernel}, follows the existence of a constant $C$ depending on $T,a$ and $\mu_0$ such that
\begin{align*}
|(F[a]*\mu(t))(y)| &\leq C(1+|y|)
\end{align*}
holds for every $y \in \R^d$ and for every $t \in [0,T]$. Hence $F[a]*\mu(t)$ is sublinear and \eqref{ttz} holds. By considering a sufficiently large compact set $K$ containing $\xi_0$, Theorem \ref{cara-global} guarantees the existence of a solution of system \eqref{eq:transpdyn} defined on $[0,T]$.

To establish uniqueness notice that, from Lemma \ref{p-Floclip}, for every compact subset $K \in \R^d$ and any $x,y \in K$, it holds
\begin{align}
\begin{split}\label{eq:uniquecara}
|(F[a]*\mu(t))(x) - (F[a]*\mu(t))(y)| &\leq \left| \int_{\R^d}F[a](x-z)d\mu(t)(z) - \int_{\R^d}F[a](y-z)d\mu(t)(z)\right| \\
&\leq \int_{\R^d} \left|F[a](x-z) - F[a](y-z)\right|d\mu(t)(z) \\
&\leq \Lip_{\widehat{K}}(F[a]) |x-y|,
\end{split}\end{align}
where $\widehat{K}$ is a compact set containing both $K$ and $B(0,R)$. Hence, uniqueness follows from \eqref{eq:uniquecara} and Lemma \ref{le:uniquecara} by taking $g_1 = g_2$, $y_1(0) = y_2(0)$ and $r = |y_1(0)|$.
\end{proof}

We can therefore consider the family of flow maps $\mathcal{T}^{\mu}_t:\R^d \rightarrow\R^d$, indexed by $t \in [0,T]$ and the choice of the mapping $\mu$, defined by
\begin{align*}
\mathcal{T}^{\mu}_t(\xi_0) = \xi(t),
\end{align*}
where $\xi:[0,T]\rightarrow\R^d$ is the unique solution of \eqref{eq:transpdyn} with initial datum $\xi_0$. The classical result \cite[Theorem 3.10]{CanCarRos10} shows that the solution of \eqref{eq:contdyn} with initial value $\mu_0$ is the unique fixed-point of the \textit{push-foward map}
\begin{align}\label{eq:fixedpoint}
\Gamma[\mu](t) := (\mathcal{T}^{\mu}_t)_{\#}\mu_0.
\end{align}

A first, basic property of the transport map is proved in the following

\begin{proposition}\label{p-transportlip}
$\ct^\mu_t$ is a locally bi-Lipschitz map, i.e. it is a bijective locally Lipschitz map, with locally Lipschitz inverse.
\end{proposition}
\begin{proof}
%Bijectivity is a consequence of the uniqueness of the solution to the corresponding ODE.
	
	%In particular,we have
	%\begin{align*}
	%	|g(t,x)-g(t,y)|\leq C_{a,\mu}|x-y|
	%\end{align*}
	%for almost every $t$ and $x_1,x_2$ with $|x_i|\leq c_{r,a,T}=(r+T\|a\|_\infty)\exp(T\|a\|_\infty)$.
 The choice $r = R$ in Lemma \ref{le:uniquecara} and the inequality \eqref{eq:uniquecara} trivially implies the following stability estimate
	\begin{align}\label{eq:liptrans}
		\bigl|\ct^\mu_t(x_0)-\ct^\mu_t(x_1)\bigr|
			\leq e^{T\,\Lip_{B(0,R)}(F[a])}|x_0-x_1|,\quad \text{ for } |x_i|\leq R\,,\quad i=0,1\,.
	\end{align}
	i.e., $\ct^\mu_t$ is locally Lipschitz.
	
	In view of the uniqueness of the solutions to the ODE \eqref{eq:transpdyn}, it is furthermore clear that, for any $t_0\in [0,T]$, the inverse of $\ct^\mu_{t_0}$ is
	given by the transport map associated to the backward-in-time ODE
\begin{align*}
\left\{\begin{aligned}
\dot{\xi}(t) &= (F[a]*\mu(t))(\xi(t)) \quad \text{ for } t \in [0,t_0),\\
\xi(t_0) &= \xi_0.
\end{aligned}\right.
\end{align*}
%\dot \(t)=\bigl(F[a]\ast\mu\bigr)(x)\,,\quad x(t_0)=x_0\,.
	However, this problem in turn can be cast into the form of an usual IVP simply by considering the reverse trajectory $\nu_t=\mu_{t_0-t}$. Then
	$y(t)=\xi(t_0-t)$ solves
	\begin{align*}
	\left\{\begin{aligned}
		\dot y(t)&=-\bigl(F[a]\ast\nu(t)\bigr)(y(t))  \quad \text{ for } t \in (0,t_0], \\
		y(0) &= \xi(t_0).
	\end{aligned}\right.
	\end{align*}
	The corresponding stability estimate for this problem then yields that the inverse of $\ct^\mu_t$ is indeed
	locally Lipschitz too (with the same local Lipschitz constant).
\end{proof}


%We can easily recover, as consequence of \eqref{gronvalla}, similar estimates for the flow map $\mathcal{T}^{\mu}_t$ as in %\cite[Lemmas 3.7 and 3.8]{CanCarRos10}
%\cite{CanCarRos10} and \cite{MFOC}.

The following Lemma and \eqref{gronvalla} are the main ingredients of the forthcoming result on continuous dependance on initial data.

\begin{lemma}\label{primstim}
Let $\mathcal{T}_1$ and $\mathcal{T}_2 \colon \R^n \to \R^n$ be two bounded Borel measurable functions. Then, for every $\mu \in \PP(\R^n)$ one has
\begin{align*}
\W_1((\mathcal{T}_1)_{\#}\mu, (\mathcal{T}_2)_{\#} \mu) \le \|\mathcal{T}_1-\mathcal{T}_2\|_{L^\infty({\rm supp}\,\mu)}.
\end{align*}
If in addition $\mathcal{T}_1$ is locally Lipschitz continuous, and $\mu$, $\nu \in \PP(\R^n)$ are both compactly supported on a ball $B(0,r)$ of $\R^n$, then
\begin{align*}
\W_1((\mathcal{T}_1)_{\#} \mu, (\mathcal{T}_1)_{\#} \nu) \le \Lip_{B(0,r)}(E_1) \W_1(\mu, \nu).
\end{align*}
\end{lemma}

\begin{proof}
See \cite[Lemma 3.11]{CanCarRos10} and \cite[Lemma 3.13]{CanCarRos10}.
\end{proof}

%\begin{lemma}\label{secstim}
%Let $H\colon \R^{2d} \to \R^{d}$ be a sublinear locally Lipschitz function and let $\mu\colon[0,T]\to \PP(\R^{2d})$ and $\nu\colon[0,T]\to \PP(\R^{2d})$ be continuous maps with respect to $\W_1$ satisfying 
%\begin{equation*}
%\supp(\mu(t)) \cup \supp(\nu(t))\subset B(0,R)
%\end{equation*}
%for every $t \in [0, T]$. Then for every $\varrho >0$ there exists a constant $L_{\varrho, R}$ such that
%$$
%\|H\star \mu(t)-H\star \nu(t)\|_{L^\infty(B(0,\varrho))}\le L_{\varrho, R}\W_1(\mu(t), \nu(t))
%$$
%for every $t \in [0, T]$.
%\end{lemma}
%
%\begin{proof}
%See \cite[Lemma 4.7]{CanCarRos10}.
%\end{proof}

\begin{theorem}\label{uniq}
Fix $T>0$  and let $\mu:[0,T]\rightarrow\mathcal{P}_1(\R^d)$ and $\nu:[0,T]\rightarrow\mathcal{P}_1(\R^d)$ be two equi-compactly supported solutions  of \eqref{eq:contdyn}. Let $\mu_0:=\mu(0)$ and $\nu_0:=\nu(0)$. Consider $R>0$ such that
\begin{align}\label{supptot}
supp(\mu(t))\cup\supp(\nu(t)) \subseteq B(0, R)
\end{align}
for every $t \in[0, T]$. Then, there exist a positive constant $\overline{C}$ depending only on $T$, $a$, $r$, and $R$ such that
\begin{equation}\label{stab}
\W_1(\mu(t), \nu(t)) \le \overline{C} \, \W_1(\mu_0, \nu_0)
\end{equation}
for every $t \in [0, T]$. In particular, equi-compactly supported solutions of \eqref{eq:contdyn} are uniquely determined by the initial datum.
\end{theorem}

\begin{proof}
Let  ${\mathcal T}^\mu_t$ and ${\mathcal T}^\nu_t$ be the flow maps associated to system \eqref{eq:transpdyn} with measure $\mu$ and $\nu$, respectively.
By \eqref{eq:fixedpoint}, the triangle inequality, Lemma \ref{p-lipkernel}, Lemma \ref{primstim} and \eqref{eq:liptrans} we have for every $t \in [0,T]$
\begin{align}
\begin{split}\label{start}
\W_1(\mu(t), \nu(t))&=\W_1(({\mathcal T}^\mu_t)_{\#} \mu_0, ({\mathcal T}^\nu_t)_{\#} \nu_0)  \\
&\le \W_1(({\mathcal T}^\mu_t)_{\#} \mu_0, ({\mathcal T}^\mu_t)_{\#} \nu_0) + \W_1(({\mathcal T}^\mu_t)_{\#} \nu_0, ({\mathcal T}^\nu_t)_{\#} \nu_0)\\
&\le e^{T \, \Lip_{B(0,R)}(F[a])} \W_1(\mu_0, \nu_0)+\|{\mathcal T}^\mu_t-{\mathcal T}^\nu_t\|_{L^\infty(B(0,R))}.
\end{split}
\end{align}

Using \eqref{gronvalla} with $y_1(0)= y_2(0)$ we get
\begin{equation}\label{stima2}
\|{\mathcal T}^\mu_t-{\mathcal T}^\nu_t\|_{L^\infty(B(0,r))}\le e^{t \, \Lip_{B(0,R)}(F[a])}\int_0^t \|F[a]* \mu(s)-F[a]* \nu(s)\|_{L^\infty(B(0,R))}\,ds.
\end{equation}

Combining \eqref{start} and \eqref{stima2} with Lemma \ref{p-lipkernel}, we have
$$
\W_1(\mu(t), \nu(t))\le e^{T \, \Lip_{B(0,R)}(F[a])} \left(\W_1(\mu_0, \nu_0)+ L_{a,R,R}\int_0^t \W_1(\mu(s), \nu(s)) \,ds\right)
$$
for every $t \in [0, T]$, where $L_{a,R,R}$ is the constant from Lemma \ref{p-lipkernel}. Gronwall's inequality now gives
$$
\W_1(\mu(t), \nu(t))\le e^{T \, \Lip_{B(0,R)}(F[a]) + L_{a,R,R}} \W_1(\mu_0, \nu_0),
$$
which is exactly \eqref{stab} with $\overline{C}= e^{T \, \Lip_{B(0,R)}(F[a]) + L_{a,R,R}}$.

Consider now two solutions of \eqref{eq:contdyn} with the same initial datum $\mu_0$. Since, from Proposition \ref{pr:exist} they both satisfy \eqref{supptot} for the given \textit{a priori known} $R$ given by \eqref{Rest}, then \eqref{stab} guarantees they both describe the same curve in $\PP(\R^d)$. This concludes the proof.
\end{proof}

\section{The error functional $E$}

As already explained in the introduction, our goal is to learn a target function $a \in X$ (which we fix throughout the section) from the observation of the dynamics $\mu$ that stems from system \eqref{eq:contdyn} with $a$ as interaction kernel, $\mu_0$ as initial datum and $T$ as finite time horizon.

A very reasonable and intuitive strategy would be to pick $a$ among those functions in $X$ which would give rise to a dynamics similar to $\mu$. In light of the close bond between $\mu$ and the empirical measures $\mu^N$ which are solutions to \eqref{eq:discrdyn} (see Proposition \ref{pr:exist}), let us address the same problem for $\mu^N$, first. In this case we deal with the discrete system \eqref{eq:discr1} and, by assumption, we know the trajectories of the agents $x^N_i(\cdot)$ \textit{and} their velocities $\dot{x}^N_i(\cdot)$ (or, at the very least, an approximation of them as difference quotients). The function $a$ should then be chosen as the function $\widehat a \in X$ minimizing the following \textit{discrete error functional}
\begin{align}\label{eq-def-error}
	\begin{split}
	E_N(\widehat a) = \frac{1}{T}\int_0^T\frac{1}{N}\sum_{i=1}^N\biggl|\frac{1}{N}\sum_{j=1}^N
			\left(\widehat a(|x^N_i(t)-x^N_j(t)|)(x^N_i(t) - x^N_j(t))-\dot{x}^N_i(t)\right)\biggr|^2 dt,
	\end{split}
\end{align}
among all functions $\widehat a \in X$. Notice that the functional $E_N$ has the remarkable property of being easily computable from the knowledge of $x^N_i$ and $\dot{x}^N_i$.

To link the discrete error functional \eqref{eq-def-error} to the problem of learning $a$ for $\mu$, notice that, by means of the empirical measure $\mu^N$, $E_N$ can be rewritten as follows
\begin{align*}
	\begin{split}
	E_N(\widehat a) & = \frac{1}{T}\int_0^T\frac{1}{N}\sum_{i=1}^N\biggl|\frac{1}{N}\sum_{j=1}^N
			\bigl(F[\widehat a]-F[a]\bigr)(x_i-x_j)\biggr|^2 dt\\
			& = \frac{1}{T}\int_0^T \int_{\R^d} \biggl|\bigl(F[\widehat a]-F[a]\bigr)\ast\mu^N(t)\biggr|^2d\mu^N(t)(x)dt,
	\end{split}
\end{align*}
This form of $E_N$ clearly gives a specific candidate for the error functional to be minimized in the case of $\mu$, that is
\begin{align*}
	E(\widehat a)=\frac{1}{T}\int_0^T \int_{\R^d} \biggl|\bigl(F[\widehat a]-F[a]\bigr)\ast\mu(t)\biggr|^2d\mu(t)(x)dt.
\end{align*}

Hence, we can now formulate a tentative strategy for the learning of $a$ given the dynamics of $\mu$ (with initial value $\mu_0\in \mathcal{P}_c(\R^d)$):
\begin{enumerate}
\item choose $N \in \N$ \textit{sufficiently large} and draw $N$ i.i.d. initial values $x^N_{0,1}, \ldots, x^N_{0,N} \sim \mu_0$. By defining $\mu^N_0(x) = \frac{1}{N}\sum^N_{i = 1} \delta(x - x^N_{0,i})$ for every $x \in \R^d$, it is well-known from \cite[Lemma 3.3]{fornahuetter} that it holds
\begin{align}\label{initiconv}
\lim_{N \rightarrow \infty} \W_1(\mu^N_0,\mu_0) = 0;
\end{align}
\item compute $\mu^N$, the solution of system \eqref{eq:contdyn} with initial datum $\mu^N_0$. By \eqref{stab} and \eqref{initiconv} then follows
\begin{align}\label{finalconv}
\lim_{N \rightarrow \infty} \W_1(\mu^N(t),\mu(t)) = 0 \quad \text{ for every } t \in [0,T];
\end{align}
\item compute a minimizer $\widehat a_N$ for $E_N$ among all functions in a proper subset $V_N \subset X$ where this computation is feasible. The convergence of trajectories \eqref{finalconv} and the condition that $V_N \hookrightarrow X$ for $N \rightarrow +\infty$ shall guarantee that $\widehat a_N$ is a \textit{sufficiently good} approximation of $a$.
\end{enumerate}

In the next sections we shall make point 3. of the list above precise and state under which conditions on the function $a$ and the error functional $E$ the above program can be successful.
%We are considering the following ``error function''
%\begin{equation}\label{eq-def-error}
%	\begin{split}
%	E_N(\widehat a)
%		&=\frac{1}{T}\int_0^T\frac{1}{N}\sum_{i=1}^N\biggl\|\frac{1}{N}\sum_{j=1}^N
%			\bigl(F[\widehat a]-F[a]\bigr)(x_i-x_j)\biggr\|_{\R^d}^2 dt\\
%		&\equiv\frac{1}{T}\int_0^T\frac{1}{N}\sum_{i=1}^N\biggl\|\frac{1}{N}\sum_{j=1}^N
%			\bigl(\widehat a(|x_i-x_j|)-a(|x_i-x_j|)\bigr)\frac{x_i-x_j}{|x_i-x_j|}\biggr\|_{\R^d}^2 dt\,,
%	\end{split}
%\end{equation}
%and we define a minimizer $\widehat a^N_V$ of it as
%\begin{equation*}
%	\widehat a^N_V=\argmin_{\widehat a\in V}E_N(\widehat a)
%\end{equation*}
%for arbitrary subspaces $V \subset X$.
%
%In order to understand the approximation properties of $\widehat a^N_V$ towards $a$ for $N\rightarrow\infty$ and $V \uparrow X$ we need to rewrite \eqref{eq-def-error} in a proper form:
%\begin{equation}\label{eq-error-2}
%	E_N(\widehat a)
%		=\frac{1}{T}\int_0^T \int_{\R^d} \biggl\|\bigl(F[a]-F[\widehat a]\bigr)\ast\mu_t^N(x)\biggr\|^2_{\R^d} d\mu_t^N(x)\,.
%\end{equation}
%This suggests a very specific counterpart of $E_N$ for $N\rightarrow\infty$ (in the spirit of the mean-field limits) given by
%
%where $\mu_t$ is the solution to the mean-field equations \eqref{eq-fixed}--\eqref{eq-mean-field} associated to \eqref{eq-dynamics}.
In order to do this, let us first look at $E$ more closely and see whether additional coercivity assumptions are required in order to ensure that $a$ is the unique minimizer of $E$.

Since by Proposition \ref{pr:exist} follows that $\supp(\mu(t)) \subseteq B(0,R)$, where $R$ is given by \eqref{Rest}, whenever $x,y \in \R^d$ are drawn from the probability distribution $\mu(t)$ the estimate
\begin{align*}
|F[\widehat a](x-y) - F[a](x-y)|\leq 2R|\widehat a(|x-y|) - a(|x-y|)|
\end{align*}
holds. It is then clearly true that
\begin{align*}
	E(\widehat a)
		\leq\frac{4R^2}{T}\int_0^T\int_{\R^d}\biggl(\int_{\R^d}\bigl|\widehat a(|x-y|)-a(|x-y|)\bigr|
			d\mu(t)(y)\biggr)^2 d\mu(t)(x) dt.
\end{align*}
Now observe that for any $\nu\in \mathcal{P}_1(\R^d)$ the following estimate holds by H\"older's inequality
\begin{align*}
	\int_{\R^d}|f(x)|d\nu(x)\leq\biggl(\int_{\R^d}|f(x)|^2 d\nu(x)\biggr)^{1/2}.
\end{align*}
Hence, $E$ can be bounded from above as
\begin{align*}
	E(\widehat a)\leq\frac{4R^2}{T}\int_0^T\int_{\R^d}\int_{\R^d}\bigl|\widehat a(|x-y|)-a(|x-y|)
		\bigr|^2 d\mu(t)(y) d\mu(t)(x) dt.
\end{align*}
Using the distance map
\begin{align*}
	d:\R^d\times\R^d\rightarrow\R_+\,,\qquad (x,y)\mapsto d(x,y)=|x-y|\,,
\end{align*}
we define by push-forward the probability measure-valued mapping $\varrho:[0,T]\rightarrow \mathcal{P}_1(\R_+)$ defined for every Borel set $A\subset\R_+$ as
\begin{align*}
	\varrho(t)(A)=(\mu(t)\otimes\mu(t))\bigl(d^{-1}(A)\bigr).
\end{align*}
With the introduction of $\varrho$ we can further estimate
\begin{align}\label{midpoint}
	E(\widehat a)\leq\frac{4R^2}{T}\int_0^T\int_{\R_+}\bigl|\widehat a(s)-a(s)\bigr|^2 d\varrho(t)(s) dt.
\end{align}

The idea, now, would be to find a proper measure $\rho$ for which we can state the equivalence
\begin{align*}
E(\widehat a) \sim \|\widehat a - a\|_{L^2(\R_+,\rho)},
\end{align*}
which would actually imply that minimizing $E$ is actually equivalent to find (an $L^2(\R_+,\rho)$-equivalent of) the interaction kernel $a$. But, in order to go on with the estimate, we need to focus our attention on the properties of the family of measures $(\varrho(t))_{t \in [0,T]}$.
%\begin{equation}\label{eq-rho}
%	\varrho(t)=d_{\#} (\mu(t)\otimes\mu(t))\,,
%\end{equation}

\subsection{The measure $\rho$}

\begin{lemma}\label{rhosc}
	For every open set $A\subseteq\R_+$ the mapping $t \in [0,R] \mapsto\varrho(t)(A)$ is lower semi-continuous, whereas for
	any compact set $A$ it is upper semi-continuous.
\end{lemma}

\begin{proof}As a first step we show that for every given sequence $(t_n)_{n \in \N}$ converging to $t\in [0,T]$ we have the weak
	convergence $\varrho(t_n)\rightharpoonup\varrho(t)$ for $n \rightarrow +\infty$. For this, in turn we first prove the weak convergence of the product measure
	$\mu(t_n)\otimes\mu(t_n)\rightharpoonup\mu(t)\otimes\mu(t)$.
	
	It is a basic property of the space $\mathcal{C}(\R^d\times\R^d)$ that it coincides with the inductive tensor product
	$\mathcal{C}(\R^d)\otimes_\varepsilon \mathcal{C}(\R^d)$. In particular, functions of the form $h=\sum_{j=1}^J f_j\otimes g_j$ with
	$f_j,g_j\in \mathcal{C}(\R^d)$, for $j=1,\ldots,J$ and $J\in\N$, are a dense subspace of $\mathcal{C}(\R^{2d})$. Hence, to prove the weak
	convergence of measures on $\R^{2d}$, we can restrict the proof to functions of this form. Due to linearity of
	integrals, this can be further reduced to simple tensor products of the form $h=f\otimes g$.
	
	For such tensor products we can directly apply Fubini's Theorem and the weak convergence
	$\mu(t_n)\rightharpoonup\mu(t)$ (which is a consequence of the continuity of $\mu$ w.r.t. the
	Wasserstein metric $\W_1$), and find
	\[
		\int_{\R^{2d}}f\otimes g\, d(\mu(t_n)\otimes\mu(t_n))
			=\int_{\R^d}f d\mu(t_n)\cdot\int_{\R^d}g d\mu(t_n)
			\stackrel{n\rightarrow\infty}{\longrightarrow}\int_{\R^d}f d\mu(t)\cdot\int_{\R^d}g d\mu(t,.
	\]
	This implies the claimed weak convergence $\varrho(t_n)\rightharpoonup\varrho(t)$, since for any
	function $f\in \mathcal{C}(\R_+)$ we have that the continuity of $d$ implies continuity of $f\circ d$, and hence
	\begin{align*}
		\int_{\R_+}f\,d\varrho(t_n)
			&=\int_{\R^{2d}}(f\circ d)(x,y)d(\mu(t_n)\otimes\mu(t_n))(x,y)\\
			&\stackrel{n\rightarrow\infty}{\longrightarrow}
				\int_{\R^{2d}}(f\circ d)(x,y)d(\mu(t)\otimes\mu(t))(x,y)
			=\int_{\R_+}f\,d\varrho(t).
	\end{align*}
	The claim now follows from general results for weakly* convergent sequences of Radon measures, see e.g. \cite[Proposition 1.62]{AFP00}.
\end{proof}

Lemma \ref{rhosc} justifies the following
\begin{definition}
The probability measure $\rho$ on the Borel $\sigma$-algebra on $\R_+$ is defined for any Borel set $A \subseteq \R_+$ as follows
\begin{align}\label{eq-rho-4}
	\rho(A):=\frac{1}{T}\int_0^T\varrho(t)(A)dt.
\end{align}
\end{definition}
Notice that Lemma \ref{rhosc} shows that \eqref{eq-rho-4} is well-defined only for sets $A$ that are open or compact in $\R_+$. This directly implies that $\rho$ can be extended to any Borel set $A$, since both families of sets provide a basis for the Borel $\sigma$-algebra on $\R_+$. Notice that, in addition, from the semicontinuity properties shown in Lemma \ref{rhosc} we infer that for any Borel set $A$ it holds
\begin{align*}
	\rho(A) = \begin{cases}
	\sup\{\rho(F) : F \subseteq A, \;F \text{ compact}\},\\
	\inf\{\rho(G) : A \subseteq G, \;G \text{ open}\},
	\end{cases}
\end{align*}
which shows that $\rho$ is a regular measure on $\R_+$.

\vspace{0.3cm}

The measure $\rho$ has a deep relationship with our learning process: it tells us which regions of $\R_+$ (the set of distances) where actually explored in the entire dynamics of the system, and hence where we can expect our learning process to be successful, since these are the zones where we do have information to reconstruct the function $a$.

We now proceed to show the absolute continuity of $\rho$ w.r.t. the Lebesgue measure on $\R_+$.

\begin{lemma}\label{lemma-AC-1}
	Let $\mu_0$ be absolutely continuous w.r.t. the $d$-dimensional Lebesgue measure $\cl^d$. Then, for every
	$t\in [0,T]$, also the measures $\mu(t)$ are absolutely continuous w.r.t. $\cl^d$.
\end{lemma}

\begin{proof}
%	{\bf Step 1:} As a first step, we note that the transport map $\ct^\mu_t$ is locally Bi-Lipschitz, i.e. it is a bijective
%	locally Lipschitz map, and its inverse is locally Lipschitz as well. Bijectivity is a consequence of the uniqueness of
%	the solution to the corresponding ODE.
%	
%	Note that with $a$ being bounded on $\R_+$ also $F[a]$ is bounded on $\R^d$, which in turn yields boundedness
%	of $F[a]\ast\mu_t$ (uniformly in $t$; see \cite[Lemma 6.4]{MFOC}). Moreover, for fixed $t$ this
%	function is locally Lipschitz continuous, thus $g(t,x)=(F[a]\ast\mu_t)(x)$ is a Carath\'eodory function. In particular,
%	we have
%	\[
%		|g(t,x_1)-g(t,x_2)|\leq C_{a,\mu}|x_1-x_2|
%	\]
%	for almost every $t$ and $x_1,x_2$ with $|x_i|\leq c_{r,a,T}=(r+T\|a\|_\infty)\exp(T\|a\|_\infty)$. This ultimately
%	implies the stability estimate
%	\[
%		\bigl|\ct^\mu_t x_0-\ct^\mu_t x_1\bigr|
%			\leq\exp\bigl(TC_{a,\mu}\bigr)|x_0-x_1|\,,\qquad |x_i|\leq r\,,\quad i=0,1\,,
%	\]
%	shown e.g. in \cite[Lemma 6.3]{MFOC}, i.e. $\ct^\mu_t$ is locally Lipschitz.
%	
%	In view of the uniqueness of the solutions to the ODE, it is furthermore clear that the inverse of $\ct^\mu_{t_0}$ is
%	given by the transport map associated to the backward ODE
%	\[
%		\dot x(t)=\bigl(F[a]\ast\mu\bigr)(x)\,,\quad x(t_0)=x_0\,.
%	\]
%	However, this problem in turn can be cast into the form of an IVP simply by putting $\nu_t=\mu_{t_0-t}$. Then
%	$y(t)=x(t_0-t)$ solves
%	\[
%		\dot y(t)=-\bigl(F[a]\ast\nu\bigr)(x)\,,\quad y(0)=x(t_0)\,.
%	\]
%	The corresponding stability estimate for this problem then yields that the inverse of $\ct^\mu_t$ is indeed
%	locally Lipschitz (with the same local constants).

	Let a Lebesgue null-set $A\subset\R^d$ be given. Put $B=(\ct^\mu_t)^{-1}(A)$,
	the image of $A$ under the inverse of the transport map $(\ct^\mu_t)^{-1}$, which by Proposition \ref{p-transportlip} is a locally Lipschitz map. The claim now follows from showing $\cl^d(B)=0$,
	since by assumption we have $\mu_0(B)=0$, which by definition gives us
	\begin{align*}
		0=\mu_0(B)=\mu_0\bigl((\ct^\mu_t)^{-1}(A)\bigr) = \mu(t)(A)\,.
	\end{align*}
	Moreover, we can reduce this further to consider only $B\cap B(0,R)$ with $R$ as in
	\eqref{Rest}, since $\mu(t)(B\setminus B(0,R))=0$ for all $t \in [0,T]$ by Proposition \ref{pr:exist}. Hence we no longer need to distinguish
	between local and global Lipschitz maps.
	
	It thus remains to show that the image of a Lebesgue null-set under a Lipschitz map is again a Lebesgue null-set. To see this,
	recall that a measurable set $A$ has Lebesgue measure zero if and only if for every $\varepsilon>0$ there exists a
	family of balls $B_1,B_2,\ldots$ (or, equivalently, of cubes) such that
	\begin{align*}
		A\subset\bigcup_n B_n\qquad\text{and}\qquad\sum_n\cl^d(B_n)<\varepsilon\,.
	\end{align*}
	Let $L$ be the Lipschitz constant of $(\ct^\mu_t)^{-1}$, and $\diam(B_n)$ the diameter. Then clearly the image of
	$B_n$ under $(\ct^\mu_t)^{-1}$ is contained in a ball of diameter at most $L\diam(B_n)$. Denote those balls by
	$\widetilde B_n$.
	Then it immediately follows
	\begin{align*}
		(\ct^\mu_t)^{-1}(A)\subset\bigcup_n\widetilde B_n\qquad\text{as well as}\qquad
		\sum_n\cl^d(\widetilde B_n)=L^d\sum_n\cl^d(B_n)<L^d\varepsilon\,.
	\end{align*}
	Thus we have found a cover for $(\ct^\mu_t)^{-1}(A)$ whose measure is bounded from above by (a multiple of) $\varepsilon$, which finally
	yields $\cl^d((\ct^\mu_t)^{-1}(A))=0$.
\end{proof}

\begin{lemma}\label{le-abs}
	Let $\mu_0$ be absolutely continuous w.r.t. $\cl^d$. Then, for all $t\in [0,T]$, the measures $\varrho(t)$ and $\rho$ are absolutely
	continuous w.r.t. $\cl^1\llcorner_{\R_+}$.
\end{lemma}

\begin{proof}
	Fix $t\in [0,T]$. By Lemma \ref{lemma-AC-1} we already know that $\mu(t)$ is absolutely continuous w.r.t.
	$\cl^d$. This immediately implies that $\mu(t)\otimes\mu(t)$ is absolutely continuous w.r.t. $\cl^{2d}$. It hence
	remains to show that $d_{\#}\cl^{2d}$ is absolutely continuous w.r.t. $\cl^1\llcorner_{\R_+}$, where $d$ is the distance function.
	
	Let $A\subset\R_+$ be a Lebesgue null-set, and put $B=d^{-1}(A)\subset\R^{2d}$. Moreover, we denote by
	$B_x=\{y\in\R^d:|x-y|\in A\}$. Then clearly $B_{x+z}=z+B_x$. Moreover, using Fubini's Theorem we obtain
	\begin{align*}
		\cl^{2d}(B)=\int_{\R^d}\cl^d(B_x)d\cl^d(x)\,.
	\end{align*}
	It thus remains to show that $\cl^d(B_x)=0$ for one single $x\in\R^d$ (and thus for all, due to translation invariance of $\cl^d$).
	However, to calculate $\cl^d(B_0)$, we can pass to polar coordinates, and once again using Fubini's Theorem
	we obtain
	\begin{align*}
		\cl^d(B_x)=\int_{\R^d}\chi_{B_0}(y)d\cl^d(y)
			=\int_{S^d}\int_{\R_+}\chi_A(r)dr d\omega=\Omega_d\cl^1(A)=0\,,
	\end{align*}
	where $\Omega_d$ is the surface measure of the unit sphere $S_d$. This proves the absolute continuity of
	$\varrho(t)$, since
	\begin{align*}
		\cl^1(A)=0\Longrightarrow\cl^{2d}(d^{-1}(A))
			\Longrightarrow (\mu(t)\otimes\mu(t))(d^{-1}(A))=0\iff\varrho(t)(A)=0\,.
	\end{align*}
	The absolute continuity of $\rho$ now follows immediately from the one of $\varrho(t)$ for every $t$ and its
	definition as an integral average \eqref{eq-rho-4}.
\end{proof}

As an easy consequence that the dynamics of our system has support uniformly bounded in time, we get the following crucial properties of the measure $\rho$.

\begin{lemma}\label{rhocompact}
	The measure $\rho$ is finite and has compact support.
\end{lemma}

\begin{proof}
To show that $\rho$ is finite, we compute
\begin{align*}
\begin{split}
\rho(\R_+)&= \frac{1}{T}\int_0^T \varrho(t)(\R_+)dt \\
%&= \frac{1}{T}\int_0^T (\mu(t) \otimes \mu(t))(d^{-1}(\R_+))dt \\
&= \frac{1}{T}\int_0^T \int_{\R^d \times \R^d} |x - y| d\mu(t)(x) d \mu(t)(y)dt\\
&<+\infty,
\end{split}
\end{align*}
since the distance function is continuous and the support of $\mu$ is uniformly bounded in time.

	Now, notice that the supports of the measures $\varrho(t)$ are the subsets of
	\begin{align*}
	K=d(B(0,R),B(0,R))=\{|x-y|:x,y\in B(0,R)\},
	\end{align*}
	where $R$ is given by \eqref{Rest}. Due to the continuity of $d$, this set $K$ is a compact subset of $\R_+$, and we then obtain
	$\supp\rho\subseteq K$.
\end{proof}

\begin{remark}
	While absolute continuity of $\mu_0$ implies the same for $\rho$, the situation is different for purely atomic
	measures $\mu_0$. On the one hand, also $\mu(t)$ is then purely atomic for every $t$, and this remains true for
	$\varrho(t)$. However, due to the averaging \eqref{eq-rho-4} involved in the definition of $\rho$, it generally cannot be atomic. For
	example, we obtain
	\begin{align*}
		\frac{1}{T}\int_0^T\delta(t) dt=\frac{1}{T}\cl^1\llcorner_{[0,T]}\,,
	\end{align*}
	as becomes immediately clear when integrating a continuous function against those kind of measures.
\end{remark}

\subsection{Coercivity assumptions and the existence of minimizers of $E_N$}

By means of $\rho$, we can continue to estimate $E$ from \eqref{midpoint} as follows,
\begin{align}
\begin{split}\label{eq-rho-3}
	E(\widehat a)&\leq\frac{4R^2}{T}\int_0^T\int_{\R_+}\bigl|\widehat a(s)-a(s)\bigr|^2 d\varrho(t)(s) dt \\
		&= 4R^2\int_{\R_+} \bigl|\widehat a(s)-a(s)\bigr|^2 d\rho(s)\\
		&= 4R^2\|\widehat a-a\|^2_{L^2(\R_+,\rho)}.
\end{split}
\end{align}

Equation \eqref{eq-rho-3} thus suggests the following additional condition to impose in order to ensure that $a$ is the unique minimizer of $E$: we assume that there exists a constant $c>0$ such that
\begin{align}\label{eq-coercive}
	E(\widehat a)\geq c\|\widehat a-a\|^2_{L^2(\R_+,\rho)}.
\end{align}
Notice that, as an easy consequence of Lemma \ref{rhocompact}, it holds
\begin{align}\label{eq:inftyimplyl2}
\|a\|^2_{L^2(\R_+,\rho)} = \int_{\R_+} \bigl|a(s)\bigr|^2 d\rho(s) \leq \|a\|_{L^{\infty}(\supp(\rho))},
\end{align}
and hence, $X\subseteq L^2(\R_+,\rho)$. Thanks to this fact and to \eqref{eq-coercive} we are able to prove the following result.

\begin{proposition}\label{uniquemin}
Assume that \eqref{eq-coercive} holds. Then $a$ is the unique minimizer of $E$ among all functions in $X$.
\end{proposition}
\begin{proof}
Notice that $E(a)=0$, and since $E(\widehat a)\geq 0$ for all $\widehat a\in X$ this implies that $a$ is a minimizer of $E$. Now suppose that $E(\widehat a)=0$ for some $\widehat a\in X$. By \eqref{eq-coercive} we obtain that $\widehat a=a$ in $L^2(\R_+,\rho)$, and by \eqref{eq:inftyimplyl2} follows that $\widehat a=a$ also in $X$.
\end{proof}

The following easy fact tells us the right ambient space where to state an existence result for the minimizers of $E_N$.

\begin{proposition}\label{XMdef}
Fix $M > 0$ and define the set
\begin{align*}
X_M = \left\{b:\R_+ \rightarrow \R_+ :
\begin{array}{cc}
b \text{ is continuous, weakly differentiable and }\\
 \|b\|_{L^{\infty}(\R_+)} + \|b'\|_{L^{\infty}(\supp(\rho))} \leq M
\end{array}
 \right\}.
\end{align*}
Then $X_M\subset X$ and it is relatively compact.
\end{proposition}
\begin{proof}
Notice that $X_M \subset X$ follows from the fact that $\rho$ has compact support. Now, consider $(\widehat a_n)_{n \in \N} \subset X_M$. The Fundamental Theorem of Calculus (which is applicable for functions in $W^{1,p}$, see \cite[Theorem 2.8]{AFP00}) tells us that, for any $r_1,r_2 \in\supp(\rho)$ it holds
	\begin{align*}
		a_n(r_1)-a_n(r_2)=\int_{r_1}^{r_2}a_n'(r)dr.
	\end{align*}
	This implies
	\begin{align*}
		\bigl|a_n(r_1)-a_n(r_2)\bigr|\leq\int_{r_1}^{r_2}|a_n'(r)|dr
			\leq \|a_n'\|_{L^p(\supp(\rho))}|r_2-r_1|.
	\end{align*}
	In particular, the functions $\widehat a_n$ are all Lipschitz continuous with Lipschitz constant uniformly bounded by
	$M$, which in turn implies equi-continuity. They are moreover pointwise uniformly equibounded, since for every $r \in \supp(\rho)$ it holds
	\begin{align*}
	|\widehat a_n(r)| \leq \|\widehat a_n\|_{L^{\infty}(\supp(\rho))} \leq \|\widehat a_n\|_{L^{\infty}(\R_+)} \leq M.
	\end{align*}
Hence from the Ascoli-Arzel\'a Theorem we can deduce the existence of a subsequence (which we do not relabel) converging uniformly on $\supp(\rho)$ to some $\widehat a \in X_M$, proving the statement.
\end{proof}

\begin{proposition}\label{ENmin}
Fix $M > 0$ and let $V$ be a closed subset of $X_M$ w.r.t. the uniform convergence on $\supp(\rho)$. Then, the minimization problem
\begin{align*}
	\text{minimize } E_N(\widehat a) \text{ among all } \widehat a \in V
\end{align*}
admits a solution.
\end{proposition}
\begin{proof}
In light of the fact that $\inf E_N \geq 0$, we can consider a minimizing sequence $(\widehat a_n)_{n \in \N} \subset V$, i.e., it holds $\lim_{n \rightarrow \infty} E_N(\widehat a_n) = \inf_{V} E_N$. By Proposition \ref{XMdef} there exists a subsequence of $(\widehat a_n)_{n \in \N}$ (which we do not relabel) converging uniformly on $\supp(\rho)$ to a function $\widehat a \in V$ (since $V$ is closed). We now show that $\lim_{n \rightarrow \infty}E_N(\widehat a_n) = E_N(\widehat a)$, from which shall follow the fact that $E_N$ attains its minimum in $V$. 
%First, notice that, since from Lemma \ref{le-abs} we have that $\rho$ is absolutely continuous w.r.t. the Lebesgue measure $\cl^1\llcorner_{\R_+}$, we have
%\begin{align*}
%\|\widehat a_n - \widehat a\|_{L^{\infty}(\supp(\rho))} \leq \|\widehat a_n - \widehat a\|_{L^{\infty}(\R_+,\rho)},
%\end{align*}
%which implies $\|\widehat a_n - \widehat a\|_{L^{\infty}(\R_+,\rho)}\rightarrow0$ as $n\rightarrow+\infty$. This means that the sequence of functions $(F[\widehat a_n])_{n \in \N}$ converges uniformly to $F[\widehat a]$ in $L^{\infty}(\R_+,\rho)$. Furthermore, the fact that the measures $\mu^N(t)$ are compactly supported in $B(0,R)$ uniformly in time (where $R$ is as in \eqref{Rest}) implies that

As a first step, notice that the uniform convergence of $(\widehat a_n)_{n \in \N}$ to $\widehat a$ on $\supp(\rho)$ and the compactness of $\supp(\rho)$, imply that the functionals $F[\widehat a_n](x-y)$ converge uniformly to $F[\widehat a](x-y)$ on $B(0,R)\times B(0,R)$ (where $R$ is as in \eqref{Rest}). Furthermore, the fact that the measures $\mu^N(t)$ are compactly supported in $B(0,R)$ uniformly in time implies that
\begin{align}
\begin{split}\label{Faest}
\sup_{x,y\in B(0,R)}|F[\widehat a_n](x-y) - F[a](x-y)| &= \sup_{x,y\in B(0,R)}|\widehat a_n(|x-y|) - a(|x-y|)| |x-y| \\
&\leq 2R \sup_{r\in \supp(\rho)} |\widehat a_n(r) - a(r)| \\
& \leq 2R(M + \|a\|_{L^{\infty}(\supp(\rho))}).
\end{split}
\end{align}
Hence, we can apply three times the dominated convergence theorem to get

\begin{align*}
\lim_{n \rightarrow \infty}E_N(\widehat a_n) &= \lim_{n \rightarrow \infty}\frac{1}{T}\int_0^T\int_{\R^d} \left| \int_{\R^d}
			\left(F[\widehat a_n](x-y)-F[a](x-y)\right)d\mu^N(t)(y)\right|^2d\mu^N(t)(x) dt\\
			&= \frac{1}{T}\int_0^T\lim_{n \rightarrow \infty}\int_{\R^d} \left| \int_{\R^d}
			\left(F[\widehat a_n](x-y)-F[a](x-y)\right)d\mu^N(t)(y)\right|^2 d\mu^N(t)(x) dt\\
			&= \frac{1}{T}\int_0^T\int_{\R^d} \left| \lim_{n \rightarrow \infty}\int_{\R^d}
			\left(F[\widehat a_n](x-y)-F[a](x-y)\right)d\mu^N(t)(y)\right|^2 d\mu^N(t)(x) dt\\
			&= \frac{1}{T}\int_0^T\int_{\R^d} \left| \int_{\R^d}
			\left(F[\widehat a](x-y)-F[a](x-y)\right)d\mu^N(t)(y)\right|^2 d\mu^N(t)(x) dt\\
&= E_N(\widehat a),
\end{align*}
which proves the statement.

%Actually, the convergence is also in $L^2(\R_+,\rho)$ by \eqref{eq:inftyimplyl2}. Furthermore, notice that $E_N(\widehat a) \leq 2R\|\widehat a - a\|_{L^2(\R_+,\rho)} < +\infty$ from \eqref{eq-rho-3}, while applying \eqref{eq-coercive} and \eqref{eq-rho-3} in sequence we can bound $E_N(\widehat a_n)$ from below as
%\begin{align*}
%E_N(\widehat a_n) & \geq c \|a - \widehat a_n\|_{L^2(\R_+,\rho)} \\
%&\geq c \left(\|a - \widehat a\|_{L^2(\R_+,\rho)} - \|\widehat a - \widehat a_n\|_{L^2(\R_+,\rho)} \right)\\
%& \geq \frac{c}{2R} E_N(\widehat a) - c \|\widehat a - \widehat a_n\|_{L^2(\R_+,\rho)}.
%\end{align*}
%Since $c = 2R$, this eventually gives us the sequence of inequalities
%\begin{align*}
%\inf E_N = \lim_{n \rightarrow +\infty}E_N(\widehat a_n) \geq E_N(\widehat a) \geq \inf E_N,
%\end{align*}
%which shows that $E_N(\widehat a) = \inf E_N$, i.e., $E_N$ attains its minimum in $\widehat X \cap X$. If now $a \in \widehat X$, to prove the uniqueness of the minimizer we can argue as in the proof of Proposition \ref{uniquemin}.
\end{proof}

\begin{remark}
The requirement to search for the minimizer inside the set $X_M$ is indeed very strong, since it implies that one not only needs to know an upper bound for the target function $a$ but also of its derivative. It is however true that such upper bounds need not be sharp, as they are only required as part of a compactness argument. Moreover, in real-life applications, these quantities may be preliminary computed thanks to a statistical analysis of the trajectories of the system under study.
\end{remark}


\section{$\Gamma$-convergence of the $E_N$ to $E$}

At the end of the last section, we have seen which are the main ingredients to ensure that our error functional $E$ has the target interaction kernel $a$ as unique minimizer (the coercivity assumption \eqref{eq-coercive}), and for the well-posedness of the minimization problem of the functionals $E_N$ (the knowledge of an upper bound for $\|a\|_{L^{\infty}(\R_+)}$ and $\|a'\|_{L^{\infty}(\supp(\rho))}$).

The last ingredient we now introduce is the key property that a family of approximation spaces $V_N$ must possess in order to ensure that the minimizers of the functionals $E_N$ are sufficiently close to those of $E$.

\begin{definition}\label{VNdef}
Let $M > 0$ be given. For every $N \in \N$, let $V_N$ be a closed subset of $X_M$ w.r.t. the convergence in $L^{\infty}(\supp(\rho))$ with the following property: for all $b\in X_M$ there exists a sequence $(b_N)_{N \in \N}$ converging uniformly to $b$ on $\supp(\rho)$ and such that $b_N\in V_N$ for every $N \in \N$.
\end{definition}

We now pass to provide a link between the minimizers of the functionals $(E_N)_{N \in \N}$ and those of $E$.

\begin{theorem}\label{thm}
	Assume $a\in X$, fix $\mu_0 \in \mathcal{P}_c(\R^d)$ and set
	\begin{align*}
	M \geq \|a\|_{L^{\infty}(\R_+)} + \|a'\|_{L^{\infty}(\supp(\rho))}.
	\end{align*}
	For every $N \in \N$, let $x^N_{0,1},\ldots,x^N_{0,N}$ be i.i. $\mu_0$-distributed and define $E_N$ as in \eqref{eq-def-error} for the solution $\mu^N$ of system \eqref{eq:contdyn} with initial datum
	\begin{align*}
	\mu^{N}_0(x) = \frac{1}{N}\sum^N_{i = 1} \delta(x - x^{N}_{0,i}), \text{ for every } x \in \R^d.
	\end{align*}
	For every $N \in \N$, let $V_N\subset X_M$ be a sequence of subspaces satisfying Definition \ref{VNdef} and consider
	\begin{align*}
		\widehat a_N\in\argmin_{\widehat a\in V_N}E_N(\widehat a).
	\end{align*}
	%(notice that $\widehat a_N\in V_N$ and that $\|\widehat a_N\|_{W^{1,\infty}(\supp(\rho))}\leq\|a\|_{W^{1,\infty}(\supp(\rho))}$ by definition).
	
	Then the sequence $(\widehat a_{N})_{N \in \N}$ converges uniformly to some continuous function $\widehat a \in X_M$ such that
	$E(\widehat a)=0$. If we additionally assume the coercivity condition \eqref{eq-coercive}, then it holds
	$\widehat a=a$.
%	Assume $a\in X\cap L_2(\R_+,\rho)$ as well as
%	\begin{equation}\label{eq-a-bounded}
%		a\in W^{1,p}_{\text{loc}}(\R_+)
%	\end{equation}
%	for some $1\leq p\leq\infty$.
%	Further assume that $E$ satisfies \eqref{eq-coercive}. Let $x_1,x_2,\ldots,x_N,\ldots$ i.i. $\mu_0$-distributed for
%	some $\mu_0\in P_c(\R^d)$, and define a sequence of finite-dimensional subspaces $V_M\subset L_2(\R_+,\rho)$
%	for $M=2,3,\ldots$ such that for all $b\in X\cap L_2(\R_+,\rho)$ with $\|b\|_{1,p}\leq\|a\|_{1,p}$
%	\begin{equation*}
%		\exists b_M\in V_M, \|b_M\|_{1,p}\leq\|a\|_{1,p}\quad\text{s.t.}\quad b_M\rightarrow b\,,
%	\end{equation*}
%	with local convergence in $W^{1,p}$.
%	
%	We define
%	\begin{equation}\label{eq-error-mod}
%		E_N(\widehat a)_p=
%		\begin{cases}
%			\frac{1}{T}\int_0^T\frac{1}{N}\sum_{i=1}^N\bigl\|\frac{1}{N}\sum_{j=1}^N
%				\bigl(\widehat a(|x_i-x_j|)-a(|x_i-x_j|)\bigr)\frac{x_i-x_j}{|x_i-x_j|}\bigr\|^2 dt\,,\\
%			\qquad\text{if }\widehat a\in V_N, \|\widehat a\|_{1,p}\leq\|a\|_{1,p}\,,\\
%			+\infty\,,\\
%			\qquad\text{if }\widehat a \in L_2(\R_+,\rho),
%				\text{but $\widehat a$ does not satisfy the conditions above.}
%		\end{cases}
%	\end{equation}
%	Accordingly, we define
%	\begin{equation}\label{eq-error-mod-2}
%		\widehat a_N=\argmin_{\widehat a\in  L_2(\R_+,\rho)}E_N(\widehat a)_p
%	\end{equation}
%	(notice that $\widehat a_N\in V_N$ and $\|\widehat a_N\|_{1,p}\leq\|a\|_{1,p}$ by definition).
%	
%	Then the sequence $(\widehat a_{N})_N$ converges uniformly to some continuous function $\overline a$ with
%	$E(\overline a)=0$. If we additionally assume the coercivity condition \eqref{eq-coercive}, then we have
%	$\overline a=a$. Furthermore, the sequence $(\widehat a_N')_N$ has a subsequence weakly converging in
%	$L_p(\R_+,\rho)$ to $\overline a'$ for every $1<p<\infty$.
\end{theorem}

We start with a technical lemma.

\begin{lemma}\label{lemma-semicontinuous-1}
	Let $(\widehat a_N)_{N \in \N}\subset L^2(\R_+,\rho)$ be a sequence of continuous functions uniformly converging to a function $\widehat a$. % with the property that there exists an $M > 0$ such that $\|\widehat a_N\|_{L^{\infty}(\supp(\rho))} \leq M$ for every $N \in \N$.
	Let the functionals $E_N$ be defined as in Theorem \ref{thm}. Then it holds
	\begin{align*}
		\lim_{N\rightarrow\infty}E_{N}(\widehat a_{N})= E(\widehat a).
	\end{align*}
\end{lemma}

\begin{proof}
	As already noticed before, from the hypothesis of Theorem \ref{thm} and \cite[Lemma 3.3]{fornahuetter} it follows $\W_1(\mu_0,\mu^N_0) \rightarrow 0$ for $N \rightarrow \infty$. Hence, from \eqref{stab} we have that $W_1(\mu(t),\mu^N(t))\rightarrow 0$ for $N\rightarrow\infty$, uniformly for a.e. $t \in [0,T]$, which in particular implies the weak convergence of the sequence of measures $(\mu^N(t))_{N \in \N}$ towards $\mu(t)$ for a.e. $t\in [0,T]$. Combining the uniform convergence of the sequence $(a_{N})_{N \in \N}$ and the weak convergence of
	$\mu^{N}(t)$ we see that the limit
	\begin{align*}
		\lim_{N\rightarrow\infty}
			\Biggl|\int_{\R^d}\bigl(F[\widehat a_{N}]-F[a]\bigr)(x-y)d\mu^{N}(t)(y)\Biggr|.
	\end{align*}
	exists for a.e. $t \in [0,T]$ and for every $x \in \R^d$: indeed, for every $\varepsilon > 0$ you can find $N_0(\varepsilon)$ such that, for all $N \geq N_0(\varepsilon)$ we have
	\begin{align*}
		\sup_{x,y \in B(0,R)}|F[\widehat a_{N}](x-y)-F[\widehat a](x-y)|
			\leq 2R \|\widehat a_{N}-\widehat a\|_{L_\infty(\supp(\rho))}\leq\varepsilon/2,
	\end{align*}
	as well as
	\begin{align*}
		\biggl|\int_{\R^d}\bigl(F[\widehat a]-F[a]\bigr)(x-y)d\mu^{N}(t)(y)
			-\int_{\R^d}\bigl(F[\widehat a]-F[a]\bigr)(x-y)d\mu(t)(y)\biggr|\leq\varepsilon/2.
	\end{align*}
	The first estimate follows from \eqref{Faest} and the uniform convergence of the $\widehat a_{N}$, while the second one follows from the continuity of
	$F[a]$ and $F[\widehat a]$ (coming from the continuity of $a$ and $\widehat a$, uniform limit of continuous functions) and the uniform weak convergence of $\mu^{N}(t)$. Hence for $N\geq N_0(\varepsilon)$ we obtain
	\begin{align*}
		\Biggl|
			&\biggl|\int_{\R^d}\bigl(F[\widehat a_{N}]-F[a]\bigr)(x-y)d\mu^{N}(t)(y)\biggr|
				-\biggl|\int_{\R^d}\bigl(F[\widehat a]-F[a]\bigr)(x-y)d\mu(t)(y)\biggr|\Biggr|\\
			&\leq\biggl|\int_{\R^d}\bigl(F[\widehat a_{N}]-F[a]\bigr)(x-y)d\mu^{N}(t)(y)
					-\int_{\R^d}\bigl(F[\widehat a]-F[a]\bigr)(x-y)d\mu(t)(y)\biggr|\\
			&\leq\Biggl|\int_{\R^d}
				\bigl(F[\widehat a_{N}]-F[\widehat a]\bigr)(x-y)d\mu^{N}(t)(y)\Biggr|\\
			&\qquad +\biggl|\int_{\R^d}\bigl(F[\widehat a]-F[a]\bigr)(x-y)d\mu^{N}(t)(y)
					-\int_{\R^d}\bigl(F[\widehat a]-F[a]\bigr)(x-y)d\mu(t)(y)\biggr|\\
			&\leq2R \|\widehat a_{N}-\widehat  a\|_{L_\infty(\supp(\rho))}\int_{\R^d}d\mu^{N}(t)(y)+\frac{\varepsilon}{2}=\varepsilon,
	\end{align*}
	which implies that, for every $t \in [0,T]$ and $x \in \R^d$, it holds
	\begin{align}\label{firstlim}
		\lim_{N\rightarrow\infty}\Biggl|\int_{\R^d}\bigl(F[\widehat a_{N}]-F[a]\bigr)(x-y)d\mu^{N}(t)(y)\Biggr|^2
			=\Biggl|\int_{\R^d}\bigl(F[\widehat a]-F[a]\bigr)(x-y)d\mu(t)(y)\Biggr|^2.
	\end{align}
	Notice that in \eqref{firstlim} we added a square and that the limit is clearly uniform in $t$ and $x$.
	
	For a.e. $t \in [0,T]$, we now pass to compute the limit
	\begin{align*}
		\lim_{N\rightarrow\infty}
			\int_{\R^d}\Biggl|\int_{\R^d}\bigl(F[\widehat a_{N}]-F[a]\bigr)(x-y)d\mu^{N}(t)(y)\Biggr|^2d\mu^N(t)(x).
	\end{align*}
	For the sake of compactness we set
	\begin{align*}
		H_N(t,x)&=\int_{\R^d}\Biggl|\int_{\R^d}\bigl(F[\widehat a_{N}]-F[a]\bigr)(x-y)d\mu^{N}(t)(y)\Biggr|^2d\mu^N(t)(x),\\
		G_N(t)&= \int_{\R^d}H_N(t,x)d\mu^N(t)(x),\\
		H(t,x)&= \int_{\R^d}\Biggl|\int_{\R^d}\bigl(F[\widehat a]-F[a]\bigr)(x-y)d\mu(t)(y)\Biggr|^2d\mu(t)(x),\\
		G(t)&= \int_{\R^d}H(t,x)d\mu(t)(x),
	\end{align*}
	and we estimate
	\begin{align*}
		|G_N(t)-G(t)|&\leq \left|\int_{\R^d}H_N(t,x)d\mu^N(t)(x) - \int_{\R^d}H_N(t,x)d\mu(t)(x)\right|\\
		&\quad + \int_{\R^d}\left|H_N(t,x) - H(t,x)\right|d\mu(t)(x).
	\end{align*}
	From the fact that the $H_N$ are continuous and bounded, and that the measures $\mu^N(t)$ are weakly converging to $\mu(t)$, it follows that for every $\varepsilon > 0$ we can find $N_0(\varepsilon)$ such that for all $N \geq N_0(\varepsilon)$ it holds
	\begin{align*}
		\left|\int_{\R^d}H_N(t,x)d\mu^N(t)(x) - \int_{\R^d}H_N(t,x)d\mu(t)(x)\right|\leq \frac{\varepsilon}{2}.
	\end{align*}
	From \eqref{firstlim} also follows that for all $N \geq N_0(\varepsilon)$ we have
	\begin{align*}
	\left|H_N(t,x) - H(t,x)\right| \leq \frac{\varepsilon}{2},
	\end{align*}
	which yields $|G_N(t)-G(t)| \leq \varepsilon$, and thus
	\begin{align*}
		\lim_{N\rightarrow\infty}
			\int_{\R^d}\Biggl|\int_{\R^d}\bigl(F[\widehat a_{N}]-&F[a]\bigr)(x-y)d\mu^{N}(t)(y)\Biggr|^2d\mu^N(t)(x) = \\
			&\int_{\R^d}\Biggl|\int_{\R^d}\bigl(F[\widehat a]-F[a]\bigr)(x-y)d\mu(t)(y)\Biggr|^2d\mu(t)(x).
	\end{align*}
	
	To prove that $\lim_{N \rightarrow \infty} E_N(\widehat a_N) = E(\widehat a)$, we are simply left to show that
	\begin{align*}
		\lim_{N\rightarrow\infty} \frac{1}{T} \int^T_0 G_N(t) dt = \frac{1}{T} \int^T_0 G(t) dt.
	\end{align*}
	But this follows easily from the dominated convergence theorem and the fact that $T$ is finite, since we can bound the functions $G_N$ uniformly from above using \eqref{Faest} as
	\begin{align*}
		|G_N(t)| & \leq \int_{\R^d}\Biggl(\int_{\R^d}\bigl|(F[\widehat a_{N}]-F[a])(x-y)\bigr|d\mu^{N}(t)(y)\Biggr)^2d\mu^N(t)(x) \\
		& \leq 4R^2 \|\widehat a_N - a \|^2_{L^{\infty}(\supp(\rho))} \\
		& \leq 4R^2(B + \|a \|_{L^{\infty}(\supp(\rho))})^2.
	\end{align*}
	Here $B$ is an appropriate bound for $\|\widehat a_N\|^2_{L^{\infty}(\supp(\rho))}$, which exists since $(\widehat a_N)_{N \in\N}$ is a uniformly convergent sequence (and thus bounded).
%	Thus applying the result from {\it arXiv-article}, we obtain
%	\begin{align*}
%		\liminf_k\frac{1}{T}\int_0^T\int_{\R^d}
%			&\Bigl\|\bigl(F[a_{N_k}]-F[a]\bigr)\ast\mu_t^{N_k}(x)\Bigr\|^2 d\mu_t^{N_k}(x) dt\\
%			&\geq\frac{1}{T}\int_0^T \int_{\R^d} \liminf_{\substack{k\rightarrow\infty,\\x'\rightarrow x}}
%				\Bigl\|\bigl(F[a_{N_k}]-F[a]\bigr)\ast\mu_t^{N_k}(x')\Bigr\|^2 d\mu_t(x) dt\\
%			&=\frac{1}{T}\int_0^T\int_{\R^d}\liminf_{k\rightarrow\infty}
%				\Bigl\|\bigl(F[a_{N_k}]-F[a]\bigr)\ast\mu_t^{N_k}(x)\Bigr\|^2 d\mu_t(x) dt\,,\\
%	\end{align*}
%	where the last line is due to continuity of the function
%	\begin{align*}
%		x'\mapsto\Bigl\|\bigl(F[a_{N_k}]-F[a]\bigr)\ast\mu_t^{N_k}(x')\Bigr\|\,.
%	\end{align*}
\end{proof}

%\begin{lemma}\label{lemma-semicontinuous-2a}
%	Let $(a_N)_N\subset L_2(\R_+,\rho)$ be a sequence of continuous functions which converges pointwise
%	$\cl^1$-almost everywhere to some function $\overline a$. Then for every $\varepsilon>0$ there exist sets
%	$K^t_\varepsilon\subset\R^d$, $t\in [0,T]$, such that $\mu_t(\R^d\setminus K^t_\varepsilon)\leq\varepsilon$ and
%	\begin{equation}\label{eq-lower-semi-2}
%		\begin{split}
%		\liminf_{N\rightarrow\infty}&E_N(a_N)\\
%			&\geq\frac{1}{T}\int_0^T\int_{\R^d}\Biggl(\Biggl\|\int_{K^t_\varepsilon}
%				\bigl(F[\bar a]-F[a]\bigr)(x-y)d\mu_t(y)\Biggr\|
%				-4\varepsilon\|a\|_\infty\Biggr )^2 d\mu_t(x)\,.
%		\end{split}
%	\end{equation}
%\end{lemma}
%
%\begin{proof}
%	{\bf Step 1:}
%	Step 2 of the proof of Lemma \ref{lemma-semicontinuous-1} can be re-used here.
%	
%	Since $\supp\mu_t^N\subset A$ (compact) uniformly w.r.t. $N$ and $t$ {\it (reference)} by Egorov's
%	Theorem for all $\varepsilon>0$ and all $t>0$ there exist measurable sets $K_\varepsilon^t\subset A$ with
%	$\mu_t(A\setminus K_\varepsilon^t)\leq\varepsilon$ such that
%	$F[\widehat a_N]\rightrightarrows F[\overline a]$ uniformly on $K_\varepsilon^t$. Splitting the integration
%	domain accordingly and using triangle inequality we find
%	\begin{align*}
%		\Biggl\|
%			&\int_{\R^d}\bigl(F[a_N]-F[a]\bigr)(x-y)d\mu_t^N(y)\Biggr\|\\
%			&=\Biggl\|\int_{K_\varepsilon^t}\bigl(F[a_N]-F[a]\bigr)(x-y)d\mu_t^N(y)
%				+\int_{A\setminus K_\varepsilon^t}\bigl(F[a_N]-F[a]\bigr)(x-y)d\mu_t^N(y)\Biggr\|\\
%			&\geq\underbrace{\Biggl\|\int_{K_\varepsilon^t}
%				\bigl(F[a_N]-F[a]\bigr)(x-y)d\mu_t^N(y)\Biggr\|}_{I_N}
%				-\underbrace{\Biggl\|\int_{A\setminus K_\varepsilon^t}
%					\bigl(F[a_N]-F[a]\bigr)(x-y)d\mu_t^N(y)\Biggr\|}_{II_N}\,.
%	\end{align*}
%	
%	For the term $I_N$ we further find by combining the uniform convergence of $a_N$ on
%	$K_\varepsilon^t$ and the weak convergence of $\mu_t^N$ that the limit $N\rightarrow\infty$ exists: For
%	$N\geq N_0(\delta)$ we have
%	\begin{equation*}
%		\|F[a_N]-F[\overline a]\|
%			=\|a_N-\overline a\|_{L_\infty(K_\varepsilon^t)}\leq\delta/2\,,
%	\end{equation*}
%	as well as
%	\begin{equation*}
%		\biggl\|\int_{K_\varepsilon^t}\bigl(F[\overline a]-F[a]\bigr)(x-y)d\mu^N_t(y)
%			-\int_{K_\varepsilon^t}\bigl(F[\overline a]-F[a]\bigr)(x-y)d\mu_t(y)\biggr\|\leq\delta/2\,,
%	\end{equation*}
%	note that continuity of $a$ and $\overline a$ (the latter holds only on $K_\varepsilon^t$!) implies continuity of
%	$F[a]$ and $F[\overline a]$. Hence for $N\geq N_0(\delta)$ we obtain
%	\begin{align*}
%		\Biggl|
%			&I-\biggl\|\int_{K_\varepsilon^t}\bigl(F[\overline a]-F[a]\bigr)(x-y)d\mu_t(y)\biggr\|\Biggr|\\
%			&\leq\biggl\|\int_{K_\varepsilon^t}\bigl(F[a_N]-F[a]\bigr)(x-y)d\mu^N_t(y)
%					-\int_{K_\varepsilon^t}\bigl(F[\overline a]-F[a]\bigr)(x-y)d\mu_t(y)\biggr\|\\
%			&\leq\Biggl\|\int_{K_\varepsilon^t}
%				\bigl(F[a_N]-F[\overline a]\bigr)(x-y)d\mu_t^N(y)\Biggr\|\\
%			&\qquad +\biggl\|\int_{K_\varepsilon^t}\bigl(F[\overline a]-F[a]\bigr)(x-y)d\mu^N_t(y)
%					-\int_{K_\varepsilon^t}\bigl(F[\overline a]-F[a]\bigr)(x-y)d\mu_t(y)\biggr\|\\
%			&\leq\int_{K_\varepsilon^t}\frac{\delta}{2}d\mu_t^N(y)+\frac{\delta}{2}\leq\delta\,,
%	\end{align*}
%	which implies
%	\begin{equation*}
%		\lim_{N\rightarrow\infty}I_N
%			=\Biggl\|\int_{K_\varepsilon^t}\bigl(F[\overline a]-F[a]\bigr)(x-y)d\mu_t(y)\Biggr\|\,.
%	\end{equation*}
%	For the term $II_N$ we first obtain
%	\begin{equation*}
%		II_N\leq 2\|a\|_\infty\int_{A\setminus K_\varepsilon^t}d\mu_t^N(y)
%			\leq 2\|a\|_\infty\int_{\R^d}\psi_\varepsilon(y)d\mu_t^N(y)\,,
%	\end{equation*}
%	where $\psi_\varepsilon$ is a bounded continuous (bump) function approximating
%	$\chi_{A\setminus K_\varepsilon^t}$ in $L_1(\mu_t)$ from above, i.e.
%	$\psi_\varepsilon\geq\chi_{A\setminus K_\varepsilon^t}$ and
%	\begin{equation*}
%		\|\psi_\varepsilon-\chi_{A\setminus K_\varepsilon^t}\|_{L_1(\mu_t)}\leq\varepsilon\,.
%	\end{equation*}
%	But then the weak convergence of $\mu_t^N$ implies
%	\begin{equation*}
%		\int_{\R^d}\psi_\varepsilon(y)d\mu_t^N(y)
%			\longrightarrow\int_{\R^d}\psi_\varepsilon(y)d\mu_t(y)\leq 2\varepsilon
%	\end{equation*}
%	by choice of $\psi_\varepsilon$ and $K_\varepsilon^t$. Put together, we thus have
%	\begin{equation*}
%		\limsup_{N\rightarrow\infty}II_N\leq 4\|a\|_\infty\varepsilon\,.
%	\end{equation*}
%	In turn, this yields
%	\begin{equation*}
%		\liminf_N\Biggl\|\int_{\R^d}\bigl(F[a_N]-F[a]\bigr)(x-y)d\mu_t^N(y)\Biggr\|
%			\geq\Biggl\|\int_{K_\varepsilon^t}\bigl(F[\overline a]-F[a]\bigr)(x-y)d\mu_t(y)\Biggr\|
%				-4\|a\|_\infty\varepsilon\,,
%	\end{equation*}
%	so far for every choice of $\varepsilon>0$ and $t>0$. Integrating over $t$ then yields \eqref{eq-lower-semi-2}.
%\end{proof}
%
%
%\begin{lemma}\label{lemma-semicontinuous-2}
%	Let $(a_N)_N\subset L_2(\R_+,\rho)$ be a sequence of continuous, weakly differentiable functions such that for all
%	$N$
%	\[
%		\|a_N\|_{W^1_1(\R_+,\rho)}\leq C_0\,,
%	\]
%	and let $(a_N)_N$ be uniformly bounded at a point.
%	
%	Then there exists a subsequence $(a_{N_k})_k$ which converges $\cl^1$-a.e.
%\end{lemma}
%
%\begin{proof}
%	If we denote by $\phi_t$ the Radon-Nicodym derivative of $\varrho_t$ w.r.t. $\cl^1$, for arbitrary fixed
%	$t\in [0,T]$ we can apply Helly's Selection Theorem to the functions $(a_N\phi_t)_N$. Then there exists a
%	subsequence $(a_{N_k}\phi_t)_k$ which converges pointwise $\cl^1$-a.e. to some
%	function $\overline a\phi_t$ of bounded variation.
%\end{proof}

\begin{proof}[\normalfont\bf Proof of Theorem \ref{thm}]
%	By the respective construction of the functionals $E_N$, the sequence of minimizers
%	$(\widehat a_N)_N$ satisfies the assumptions of one of the above lemmas. Hence it has a pointwise $\rho$-a.e. or
%	uniformly, respectively, convergent subsequence with limit function $\overline a$. We wish to show that
%	$\overline a$ is a minimizer of $E$, then by \eqref{eq-coercive} we have $\overline a=a$. Since in this way for
%	every subsequence we can extract a subsubsequence converging to the same limit function $a$, we can infer that
%	the entire sequence converges to $a$. For simplicity we will only treat the case $p=\infty$; the case $1<p<\infty$
%	can be reduced to the proof for $p=1$ in view of $W^1_p\hookrightarrow W^1_1$; finally, the case $p=1$ uses the
%	same arguments as $p=\infty$, with Lemma \ref{lemma-semicontinuous-1} replaced by Lemmas
%	\ref{lemma-semicontinuous-2a} and \ref{lemma-semicontinuous-2}.
	The sequence of minimizers $(\widehat a_N)_{N \in \N}$ is by definition a subset of $X_M$, hence by Proposition \ref{XMdef} it admits a subsequence $(\widehat a_{N_k})_{k \in \N}$ uniformly converging to a function $\widehat a \in X_M$.
	
	To show the optimality of $\widehat a$, let $b\in X_M$ be given. By Definition \ref{VNdef}, we can find a sequence $(b_N)_{N \in \N}$ converging uniformly to $b$ on $\supp(\rho)$ such that $b_N\in V_N$ for every $N\in \N$. Hence, by Lemma \ref{lemma-semicontinuous-1}, it holds
	\begin{align*}
		E(b)=\lim_{N\rightarrow\infty}E_{N}(b_{N}).
	\end{align*}
	Now, by the optimality of $\widehat a_{N_k}$ and again by Lemma \ref{lemma-semicontinuous-1}, follows that
	\begin{align*}
		E(b)=\lim_{N\rightarrow\infty}E_N(b_N)
			= \lim_{k \rightarrow\infty}E_{N_k}(b_{N_k})
			\geq\lim_{k \rightarrow\infty}E_{N_k}(\widehat a_{N_k})
			= E(\widehat a)\,.
	\end{align*}
	We can therefore conclude the fundamental estimate
	\begin{align}\label{fond}
		E(b)\geq E(\widehat a),
	\end{align}
	which holds for every $b \in X_M$. In particular, \eqref{fond} applies to $b=a\in X_M$ (by the particular choice of $M$), which finally implies
	\begin{align*}
		0=E(a)\geq E(\widehat a)\geq 0\Longrightarrow E(\widehat a)=0,
	\end{align*}
	showing that $\widehat a$ is a minimizer of $E$. In case \eqref{eq-coercive} holds, by Proposition \ref{uniquemin} follows $\widehat a=a$, as desired.
\end{proof}


%\section{New model}
%
%The scope of this note is to support a model which differs from the one proposed at Duke in two fundamental aspects:
%
%1.) In the dynamical systems we are considering, of the type
%\begin{equation}\label{eq-dynamics}
%	\dot x_i=\frac{1}{N}\sum_{j=1}^N a(|x_i-x_j|)\frac{x_j-x_i}{|x_j-x_i|}\,,\quad i=1,\ldots,N\,,
%\end{equation}
%we cannot distinguish between different particles. Hence assuming an asymmetric distribution of initial conditions $(x_1(0),\ldots,x_N(0))\sim\pi_0$, where $\pi_0\neq\bigotimes_{i=1}^N\mu_0$ is perhaps a ``conceptual crime.'' Hence we are forced to consider distributions of the type $\pi_0=\bigotimes_{i=1}^N\mu_0$ leading to the well-established theory of the so-called BBGKY-hierarchy and mean-field limits. This implies that the only relevant underlying dynamics is the transport of the indicated probability $\mu_0$ along the characteristics induced by \eqref{eq-dynamics} (more explanations below).
%
%2.) While at Duke there has been an attempt to parallel the work of Binev, Cohen, Dahmen, DeVore and Temlyakov on piecewise polynomial approximations induced by least squares. It is quite clear to us (as explained below) that the reference infinite dimensional variational problem approximated by the finite dimensional sampling counterpart is {\bf not} a least squares in the strict sense that the theory by BCDDT has to be significantly (?) modified and adapted. This means no straightforward application of it!
%
%\subsection{Mean-field limit}
%
%Let us reformulate \eqref{eq-dynamics} as a discrete instance of a mean-field PDE. For that we introduce the empirical measure $\mu_t^N=\frac{1}{N}\sum_{j=1}^N\delta_{x_i(t)}$ supported on the trajectories of \eqref{eq-dynamics}. We can then rewrite \eqref{eq-dynamics} in the following form
%\begin{align}
%	\dot x_i
%		&=\frac{1}{N}\sum_{j=1}^N a(|x_i-x_j|)\frac{x_j-x_i}{|x_j-x_i|}\notag\\
%		&=\int_{\R^d} a(|x_i-y|)\frac{y-x_i}{|y-x_i|}d\mu_t^N(y)
%			=\bigl(F[a]\ast\mu_t^N\bigr)(x_i)\,,
%\end{align}
%where we introduced the notation
%\[
%	F[a](\xi)=\frac{\xi}{|\xi|}a(|\xi|)\,,\quad\xi\in\R^d\setminus\{0\}\,.
%\]
%Based on this formulation and given a probability measure-valued mapping $\mu:[0,T]\rightarrow P_1(\R^d)$ (with values on the probability with bounded first moments) and one point $x_0\in\R^d$ we define the corresponding trajectory in $\R^d$ as the solution of the IVP
%\begin{equation}\label{eq-trajectory}
%	\left\{\begin{split}
%		\dot x(t)&=\bigl(F[a]\ast\mu\bigr)(x)\,,\\
%		x(0)&=x_0
%	\end{split}\right.
%\end{equation}
%We denote the associated flow map by $\mathcal{T}^\mu_t(x_0):=x(t)$; accordingly, for $\mu_0\in P_c(\R^d)$ (i.e. $\mu_0$ is a compactly supported probability measure on $\R^d$), we define further the fixed point solution $\mu:[0,T]\rightarrow P_c(\R^d)$ of
%\begin{equation}\label{eq-fixed}
%	\mu(t)\equiv \mu_t=\mathcal{T}^\mu_t\#\mu_0
%\end{equation}
%via the push-forward of $\mu_0$ by means of the transport/flow map $\mathcal{T}^\mu_t(x_0)$ defined according to \eqref{eq-trajectory}. It's possible to prove (see Section 8 of Ambrosio, Gigli, Sarar\'e 2008) that $\mu$ is also the solution to the equation
%\begin{equation}\label{eq-pushforward}
%	\int_{\R^d}\varphi(x)d\mu_t(x)-\int_{\R^d}\varphi(x)d\mu_0(x)
%		=\int_0^t \int_{\mathbb R^d} \nabla\varphi(x)\cdot \bigl(F[a]\ast\mu_s\bigr)(x)d\mu_s(x) ds
%\end{equation}
%$\forall\varphi\in C^1(\R^d)$ or \underline{formally} by saying that $\mu_t$ is the weak solution of the PDE
%\begin{equation}\label{eq-mean-field}
%	\frac{\partial\mu_t}{\partial t}=-\nabla\cdot\Bigl[\bigl(F[a]\ast\mu_t\bigr)\mu_t\Bigr]\,.
%\end{equation}
%The equation \eqref{eq-mean-field} is called the mean-field equation associated to \eqref{eq-dynamics} for $N\rightarrow\infty$ and it can be derived also via BBGKY-hierarchy (which clarifies how the indistinguishability of particles results in the evolution of a single probability $\mu_t$).
%
%\subsection{Stability of solution of \eqref{eq-pushforward} and \eqref{eq-mean-field}}
%
%We also introduce the $1$-Wasserstein distance on $P_1(\R^d)$,
%\begin{equation}\label{eq-wasserstein}
%	W_1(\mu,\nu)=\sup_{\Lip\varphi\leq 1}\biggl|\int_{\R^d}\varphi d\mu-\int_{\R^d}\varphi d\nu\biggr | \,,
%	\quad\mu,\nu\in P_1(\R^d)\,.
%\end{equation}
%Given $\mu_0,\nu_0\in P_c(\R^d)$ (compact support particularly entails finite first moment), and denoting by $\mu_t$ and $\nu_t$, respectively, the corresponding solutions of \eqref{eq-fixed}--\eqref{eq-mean-field} then it is possible to show that
%\begin{equation}
%	W_1(\mu_t,\nu_t)\leq C(T)W_1(\mu_0,\nu_0)
%\end{equation}
%for all $t\in [0,T]$. Notice that, as $\mu_t^N=\frac{1}{N}\sum_{j=1}^N\delta_{x_i(t)}$ is a particular solution of \eqref{eq-fixed}--\eqref{eq-mean-field}, for $x_1,x_2,\ldots,x_N,\ldots$ i.i. $\mu_0$-distributed points, we  conclude
%\begin{equation}\label{eq-wasserstein-discret}
%	W_1(\mu_t,\mu_t^N)\leq C(T)W_1(\mu_0,\mu_0^N)\stackrel{N\rightarrow\infty}{\longrightarrow}0
%\end{equation}
%for all $t\in [0,T]$.
%
%For future reference we note that the family of measures $\mu=(\mu_t)_t$ is equi-compactly supported, i.e. there exists a compact set $K_\mu$ such that
%\begin{equation}\label{eq-equi-compact}
%	\supp\mu_t\subset K_\mu\quad\text{for all}\quad t\in [0,T]\,.
%\end{equation}
%Moreover, their first moments are bounded.
%
%\subsection{Learning $a$}


%\section{DeVore et.al.}
%
%The setting: $X\subset\R^d$ bounded domain, $Y=\R$, and $Z=X\times Y$. Moreover, $\rho$ is an unknown probability measure on $Z$, and $\rho_X$ the corresponding marginal measure on $X$, i.e. $\rho_X(A)=\rho(A\times Y)$. For $f\in L_2(X,\rho_X)$, $f:X\rightarrow Y$, define the functional
%\[
%	\mathcal{E}(f)=\int_Z (y-f(x))^2 d\rho\,.
%\]
%Objective: Find the minimizer of $\mathcal{E}$, or equivalently, minimize $\|f-f_\rho\|_{L_2(\rho)}$.
%
%Data: Independent samples $(x_j,y_j)$ with distribution $\rho$.
%
%Approach: For a given subspace $V$ define $f_V$ as the minimizer of the approximate (empirical) functional
%\[
%	\mathcal{E}_{\mathbf{z}}(f)=\frac{1}{m}\sum_{j=1}^m(y_j-f(x_j))^2\,,
%\]
%which clearly can be rewritten as integration against the empirical measure
%$\rho_m=\frac{1}{m}\sum_{j=1}^m\delta_{x_j}$, with the identification $y_j=f_\rho(x_j)$.
%
%\vspace{1cm}
%
%i) In our setting, together with the coercivity assumption, we know that the only minimizer of our functional $E$ is the function $a$. In that case, minimizing $E$ is equivalent to minimizing $\|\cdot-a\|_{L_2(\rho)}$, in the sense that they have the same unique global minimizer (at least $\rho$-a.e.) (which coincides with the exact solution of our learning problem).
%
%ii) In the DeVore-Article, while the measure $\rho$ is not known, it is assumed that one can obtain independent samples. For us, we may sample the initial values according to $\mu_0$, which in turn leads to independent samples of $\mu_t$, but do we get also samples for our measure $\rho$ that way?
%
%\pagebreak
%
%\section{Analysis}
%
%We start with an estimate for the sampling error, i.e. the error contribution incurred on a fixed partition $\Lambda$ due to inexact projections.
%
%\begin{theorem}[Sampling error]
%	Let $\Lambda$ be a fixed partition. Then
%	\[
%		P\bigl(\|P_\Lambda a-a^N_M\|_{L_2(\rho)}>\eta\bigr)
%			\leq 4M\exp\Bigl(-\frac{3N^2\eta^2}{256MB_a^2}\Bigr)
%	\]
%	where $a^N_M=\argmin_{b\in V_M}E_N(b)$, $M=\#\Lambda$ and $B_a=\|a\|_\infty$.
%\end{theorem}
%
%\begin{proof}
%	We follow the proof of DeVore et. al.
%	
%	{\bf Step 1:} By definition we can write
%	\[
%		\|P_\Lambda a-a^N_M\|^2_{L_2(\rho)}
%			=\sum_{I\in\Lambda}|c_I-c^N_I|^2\rho(I)\,.
%	\]
%	With the function $a$, also the coefficients $c_I$ and $c_{I,N}$ are always bounded ({\bf add details}). Therefore,
%	if we split the partition into
%	\[
%		\Lambda^-=\Bigl\{I\in\Lambda:\rho(I)\leq\frac{\eta^2}{8NM^2}\Bigr\}
%	\]
%	and $\Lambda^+=\Lambda\setminus\Lambda^-$. Then we first obtain
%	\[
%		\sum_{I\in\Lambda^-}|c_I-c^N_I|^2\leq\frac{\eta^2}{2}
%	\]
%	(i.e. with probability $1$). To prove the theorem it is hence sufficient to show
%	\[
%		P\Bigl(|c_I-c^N_I|^2\geq\frac{\eta^2}{2M\rho(I)}\Bigr)
%			\leq 4\exp\Bigl(-\frac{3N^2\eta^2}{256MB_a^2}\Bigr)\,,
%	\]
%	because of the union bound and $\#\Lambda^+\leq\#\Lambda=M$. To see this estimate, we write
%	$\rho^N(I)=(1+\beta_I)\rho(I)$, so that in case $|\beta_I|\leq\frac{1}{2}$ we find
%	\begin{align*}
%		|c_I-c^N_I|
%			&=\Bigl|\frac{\alpha_I}{\rho_I}-\frac{\alpha^N_I}{\rho^N_I}\Bigr|
%				=\frac{1}{\rho(I)(1+\beta_I)}\bigl|\alpha^N_I-\alpha_I-\beta_I\alpha_I|\\
%			&\leq\frac{2}{\rho(I)}\bigl(|\alpha^N_I-\alpha_I|+|\alpha_I\beta_I|\bigr)\,.
%	\end{align*}
%	If we further require
%	\[
%		|\alpha_I-\alpha^N_I|\leq\frac{\eta\sqrt{\rho(I)}}{4\sqrt{2M}}
%	\]
%	as well as
%	\[
%		|\rho^N(I)-\rho(I)|\leq\min\Bigl(\frac{1}{2}\rho(I),\frac{\eta\rho(I)^{3/2}}{4\sqrt{2M}|\alpha_I|}\Bigr)
%	\]
%	we conclude (note $\alpha_I\beta_I=\frac{\alpha_I}{\rho(I)}(\rho^N(I)-\rho(I))$)
%	\begin{align*}
%		|c_I-c^N_I|
%			&\leq\frac{2}{\rho(I)}\bigl(|\alpha^N_I-\alpha_I|+|\alpha_I\beta_I|\bigr)\\
%			&\leq\frac{2}{\rho(I)}\frac{\eta\sqrt{\rho(I)}}{4\sqrt{2M}}
%				+\frac{2}{\rho(I)}\frac{|\alpha_I|}{\rho(I)}\rho^N(I)-\rho(I)|\\
%			&\leq\frac{\eta}{2\sqrt{2M\rho(I)}}
%				+\min\Bigl(\frac{|\alpha_I|}{\rho(I)},\frac{\eta}{2\sqrt{2M\rho(I)}}\Bigr)
%				\leq\frac{\eta}{\sqrt{2M\rho(I)}}\,.
%	\end{align*}
%	We thus obtain
%	\begin{align}
%		P\Bigl(|
%			&c^N_I-c_I|^2\geq\frac{\eta^2}{2M\rho(I)}\Bigr)\notag\\
%			\label{eq-prob-1}
%			&\leq P\Bigl(|\alpha^N_I-\alpha_I|\geq\frac{\eta\sqrt{\rho(I)}}{4\sqrt{2N}}\Bigr)
%				+P\Bigl(|\rho^N(I)-\rho(I)|\geq
%					\min\bigl(\frac{1}{2}\rho(I),\frac{\eta\rho(I)^{3/2}}{4\sqrt{2M}|\alpha_I|}\bigr)\Bigr)\,.
%	\end{align}
%	
%	{\bf Step 2:}
%	These probabilities we now estimate with the help of Bernstein's inequality. We recall, if $\zeta_i$ are $m$
%	independent realizations of a bounded random variable $\zeta$ with $|\zeta(\omega)-\mathbb{E}(\zeta)|\leq B$ and
%	$\text{Var}(\zeta)=\sigma^2$, then for every $\varepsilon>0$ it follows
%	\[
%		P\biggl(\Bigl|\frac{1}{m}\sum_{i=1}^m\zeta_i-\mathbb{E}(\zeta)\Bigr|\geq\varepsilon\biggr)
%			\leq 2e^{-\frac{m\varepsilon^2}{2(\sigma^2+B\varepsilon/3)}}\,.
%	\]
%	{\bf needs reference}
%	
%	Since we have no direct access to $\rho$-distributed random variables, we have to rely on random variables
%	distributed according to the initial distribution $\mu_0$. We therefore write
%	\begin{align*}
%		\rho(I)
%			&-\rho^N(I)\\
%			&=\frac{1}{T}\int_0^T\int_{\R^{2d}}\chi_{d^{-1}(I)}d(\mu_t\otimes\mu_t)dt
%				-\frac{1}{N^2}\sum_{i,j}\frac{1}{T}\int_0^T\chi_I(|\ct^\mu_t x_i-\ct^\mu_t x_j|)dt\\
%			&=\frac{1}{T}\int_0^T\int_{\R^{2d}}\chi_{\Phi_t^{-1}(I)}(x,y)d(\mu_0\otimes\mu_0)(x,y)\,dt
%						-\frac{1}{N^2}\sum_{i,j}\frac{1}{T}\int_0^T\chi_{\Phi_t^{-1}(I)}(x_i,x_j)dt\\
%			&=\int_{\R^{2d}}\frac{1}{T}\int_0^T\chi_{\Phi_t^{-1}(I)}(x,y)dt\,d(\mu_0\otimes\mu_0)
%						-\frac{1}{N^2}\sum_{i,j}\frac{1}{T}\int_0^T\chi_{\Phi_t^{-1}(I)}(x_i,x_j)dt\,,
%	\end{align*}
%	where $\Phi=(\ct^\mu_t\otimes\ct^\mu_t)\circ d$, i.e. $\Phi_t(x,y)=|\ct^\mu_t x-\ct^\mu_t y|$. Therein, in the last
%	line the inner integral has to be interpreted as a Bochner-integral. Hence defining
%	\[
%		\zeta=\frac{1}{T}\int_0^T\chi_{\Phi_t^{-1}(I)}dt\,,
%	\]
%	again in the sense of a Bochner integral in $L_1(\R^{2d},\mu_0\otimes\mu_0)$, we can write
%	\[
%		\rho(I)-\rho^N(I)
%			=\int_{\R^{2d}}\zeta(x,y)d(\mu_0\otimes\mu_0)(x,y)
%				-\frac{1}{N^2}\sum_{i,j}\zeta(x_i,x_j)\,.
%	\]
%	Let $x_i$, $i=1,\ldots,N$, be independent samples of $\mu_0$. Then the pairs $(x_i,x_j)$, $i,j=1,\ldots,N$,
%	are independent w.r.t. $\mu_0\otimes\mu_0$. Thus we can apply Bernstein's inquality to $\zeta$, which clearly is
%	bounded by $1$ (thus $B=2$ here), with $\mathbb{E}(\zeta)=\rho(I)$ and
%	$\text{Var}(\zeta)=\rho(I)(1-\rho(I))\leq\rho(I)$. We then obtain in the case
%	$\frac{1}{2}\rho(I)\geq\frac{\eta\rho(I)^{3/2}}{4\sqrt{2M}|\alpha_I|}$
%	\begin{align*}
%		P\biggl(|\rho(I)-\rho^N(I)|\geq\frac{\eta\rho(I)^{3/2}}{4\sqrt{2M}|\alpha_I|}\biggr)
%			&\leq 2\exp\Bigl(-\frac{N^2\eta^2\rho(I)^3}
%				{64M|\alpha_I|^2(\rho(I)+\frac{2}{3}\frac{\eta\rho(I)^{3/2}}{4\sqrt{2M}|\alpha_I|})}\Bigr)\\
%			&\leq 2\exp\Bigl(-\frac{N^2\eta^2\rho(I)^3}{256M B_a^2\rho(I)^3/3}\Bigr)
%				=2\exp\Bigl(-\frac{3N^2\eta^2}{256M B_a^2}\Bigr)
%	\end{align*}
%	where we used the simple estimate $|\alpha_I|\leq B_a\rho(I)$. In the case
%	$\frac{1}{2}\rho(I)\leq\frac{\eta\rho(I)^{3/2}}{4\sqrt{2M}|\alpha_I|}$ we find
%	\begin{align*}
%		P\bigl(|\rho(I)-\rho^N(I)|\geq\tfrac{1}{2}\rho(I)\bigr)
%			&\leq 2\exp\Bigl(-\frac{N^2\rho(I)^2}{8(\rho(I)+\rho(I)/3}\Bigr)\\
%			&=2\exp\Bigl(-\frac{3}{32}N^2\rho(I)\Bigr)
%				\leq 2\exp\Bigl(-\frac{3N^2\eta^2}{256MB_a^2}\Bigr)\,,
%	\end{align*}
%	where in the last step we used $I\in\Lambda^+$. This takes care of the second probability in \eqref{eq-prob-1}. To
%	deal with the first one, we now apply Bernstein's inequality with
%	\[
%		\zeta_a(x,y)
%			=\frac{1}{T}\int_0^T a\bigl(\Phi_t\bigr)\chi_{\Phi_t^{-1}(I)} dt\,,
%	\]
%	again in the sense of Bochner integrals. With this definition we can write
%	\[
%		\alpha_I-\alpha^N_I
%			=\int_{\R^{2d}}\zeta_a(x,y)d(\mu_0\otimes\mu_0)(x,y)
%				-\frac{1}{N^2}\sum_{i,j}\zeta_a(x_i,x_j)\,.
%	\]
%	Moreover, we have $\mathbb{E}(\zeta_a)=\alpha_I$, $|\zeta(x,y)-\mathbb{E}(\zeta)|\leq 2B_a$ and
%	$\text{Var}(\zeta)\leq B_a^2\rho(I)$. Thus Bernstein's inequality yields
%	\begin{align*}
%		P\biggl(|\rho(I)-\rho^N(I)|\geq\frac{\eta\sqrt{\rho(I)}}{4\sqrt{2M}}\biggr)
%			&\leq 2\exp\Bigl(-\frac{N^2\eta^2\rho(I)}
%				{64M(B_a^2\rho(I)+\frac{2B_a\eta\sqrt{\rho(I)}}{12\sqrt{2M}})}\Bigr)\\
%			&\leq 2\exp\Bigl(-\frac{N^2\eta^2\rho(I)}{64M(B_a^2\rho(I)+\frac{4B_a^2\rho(I)}{12})}\Bigr)
%					=2\exp\Bigl(-\frac{3N^2\eta^2}{256MB_a^2}\Bigr)\,.
%	\end{align*}
%	Here we once more used $I\in\Lambda^+$. This completes the proof.
%\end{proof}
%
%{\bf TODO: Include Lemma which shows that $\zeta$ and $\zeta_a$ are well-defined functions from $L_1$ (particularly: measurable); equivalently that the mentioned Bochner integral exist.}


\bibliographystyle{abbrv}
\bibliography{biblio}	
\addcontentsline{toc}{chapter}{biblio}

\end{document}
